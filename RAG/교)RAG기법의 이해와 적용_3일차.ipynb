{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸŒ¼ RAGê¸°ë²•ì˜ ì´í•´ì™€ ì ìš© - 3ì°¨ì‹œ(24.12.02)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RMARKET\\AppData\\Local\\Temp\\ipykernel_17708\\3262330552.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs = {\n",
    "        'human' : 'ì•ˆë…•í•˜ì„¸ìš” íœ´ëŒ€í°ì„ êµ¬ë§¤í•˜ëŸ¬ ì™”ìŠµë‹ˆë‹¤'\n",
    "    },\n",
    "    outputs = {\n",
    "        'ai' : 'ì•ˆë…•í•˜ì„¸ìš”. ìƒˆ íœ´ëŒ€í°ì„ êµ¬ë§¤í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤!'\n",
    "    }\n",
    ")\n",
    "# ì„ ì…ì„ ì¶œë¡œ ë©”ëª¨ë¦¬ë¥¼ ì½ëŠ”ë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: ì•ˆë…•í•˜ì„¸ìš” íœ´ëŒ€í°ì„ êµ¬ë§¤í•˜ëŸ¬ ì™”ìŠµë‹ˆë‹¤\\nAI: ì•ˆë…•í•˜ì„¸ìš”. ìƒˆ íœ´ëŒ€í°ì„ êµ¬ë§¤í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤!\\nHuman: ì•ˆë…•í•˜ì„¸ìš” íœ´ëŒ€í°ì„ êµ¬ë§¤í•˜ëŸ¬ ì™”ìŠµë‹ˆë‹¤\\nAI: ì•ˆë…•í•˜ì„¸ìš”. ìƒˆ íœ´ëŒ€í°ì„ êµ¬ë§¤í•˜ì‹ ë‹¤ë‹ˆ ê¸°ì©ë‹ˆë‹¤!'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "CLASS\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith(\"CLASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model = 'gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', 'ë„ˆëŠ” ì¹œì ˆí•œ ì±—ë´‡ì´ì•¼'),\n",
    "        MessagesPlaceholder(variable_name = 'chat_history'),\n",
    "        ('human', \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True, memory_key='chat_history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnablePassthrough.assign(\n",
    "    chat_history = RunnableLambda(memory.load_memory_variables) | itemgetter('chat_history')\n",
    ")\n",
    "# ë©”ëª¨ë¦¬ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œ + chat_historyë§Œ getí•˜ê¸°!!!\n",
    "# ì „ì²´ ì…ë ¥ë°ì´í„°ì—ì„œ chat_historyê°’ë§Œ ê°€ì ¸ì˜¤ê¸° -> ëŒ€í™”ì´ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = runnable | prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•ˆë…•í•˜ì„¸ìš”, ê¸¸ë™ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?\n"
     ]
    }
   ],
   "source": [
    "respone = chain.invoke({'input' : 'ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì œ ì´ë¦„ì€ ê¸¸ë™ì…ë‹ˆë‹¤'})\n",
    "print(respone.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': []}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({}) # ì•„ì§ ë¹„ì–´ìˆê¸° ë•Œë¬¸ì— ìˆ˜ë™ìœ¼ë¡œ ë„£ì–´ì¤˜ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({'human' : 'ë§Œë‚˜ì„œ ë°˜ê°’ìŠµë‹ˆë‹¤. ì œ ì´ë¦„ì€ ê¸¸ë™ì…ë‹ˆë‹¤'}, {'ai' : respone.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, ê¸¸ë™ë‹˜ì´ë¼ê³  í•˜ì…¨ì£ . ë§ë‚˜ìš”?\n"
     ]
    }
   ],
   "source": [
    "respone = chain.invoke({'input' : 'ì œ ì´ë¦„ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ê¸°ì–µí•˜ì‹œëƒìš”?'})\n",
    "print(respone.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({'human' : 'ì œ ì´ë¦„ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ê¸°ì–µí•˜ì‹œë‚˜ìš”?'}, {'ai' : respone.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': [HumanMessage(content='ë§Œë‚˜ì„œ ë°˜ê°’ìŠµë‹ˆë‹¤. ì œ ì´ë¦„ì€ ê¸¸ë™ì…ë‹ˆë‹¤', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='ì•ˆë…•í•˜ì„¸ìš”, ê¸¸ë™ë‹˜! ë§Œë‚˜ì„œ ë°˜ê°‘ìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ë„ì™€ë“œë¦´ê¹Œìš”?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='ì œ ì´ë¦„ì´ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ê¸°ì–µí•˜ì‹œë‚˜ìš”?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='ë„¤, ê¸¸ë™ë‹˜ì´ë¼ê³  í•˜ì…¨ì£ . ë§ë‚˜ìš”?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k = 2, return_messages=True, memory_key='chat_history') \n",
    "# ìµœê·¼ ëŒ€í™”ë§Œ ì¼ì • ê°œìˆ˜(k)ë¡œ ì €ì¥í•¨ -> ì¡°ê¸ˆ ë” ìµœê·¼ ëŒ€í™”ì— ì§‘ì¤‘ í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_chain(memory, query):\n",
    "    chat_history = RunnablePassthrough.assign(\n",
    "        chat_history = RunnableLambda(memory.load_memory_variables) | itemgetter(memory.memory_key)\n",
    "    )\n",
    "    llm = ChatOpenAI(model = 'gpt-4o', temperature=0)\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            ('system', 'ë„ˆëŠ” ì¹œì ˆí•œ AI ë¹„ì„œì•¼'),\n",
    "            MessagesPlaceholder(variable_name='chat_history'),\n",
    "            ('human', \"{input}\")\n",
    "        ]\n",
    "    )\n",
    "    chain = chat_history | prompt | llm | StrOutputParser()\n",
    "    # StrOutputParser() : ì¶œë ¥ë˜ëŠ” ê°’ì„ ìë™ìœ¼ë¡œ íŒŒì‹±(ë¶ˆí•„ìš”í•œ ê°œí–‰ë¬¸ì, íŠ¹ìˆ˜ê¸°í˜¸ ë“±ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬)\n",
    "    answer = chain.invoke({'input' : query})\n",
    "    memory.save_context(inputs = {'human' : query}, outputs={'ai' : answer})\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai :  ì¶”ìš´ ë‚ ì”¨ì—ëŠ” ëª¸ì„ ë”°ëœ»í•˜ê²Œ í•´ì¤„ ìˆ˜ ìˆëŠ” ìŒì‹ì„ ë¨¹ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ì¶”ìš´ ë‚ ì”¨ì— ì–´ìš¸ë¦¬ëŠ” ìŒì‹ ëª‡ ê°€ì§€ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **ê¹€ì¹˜ì°Œê°œ**: ë§¤ì½¤í•˜ê³  ëœ¨ê±°ìš´ êµ­ë¬¼ë¡œ ëª¸ì„ ë”°ëœ»í•˜ê²Œ í•´ì¤ë‹ˆë‹¤.\n",
      "2. **ëœì¥ì°Œê°œ**: êµ¬ìˆ˜í•œ ë§›ê³¼ í•¨ê»˜ ë‹¤ì–‘í•œ ì±„ì†Œì™€ ë‘ë¶€ë¥¼ ë„£ì–´ ì˜ì–‘ê°€ë„ ë†’ìŠµë‹ˆë‹¤.\n",
      "3. **ì‚¼ê³„íƒ•**: ë‹­ê³ ê¸°ì™€ ì¸ì‚¼, ëŒ€ì¶” ë“±ì„ ë„£ì–´ ë“ì¸ êµ­ë¬¼ë¡œ ë³´ì–‘ì‹ìœ¼ë¡œ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "4. **ì¹¼êµ­ìˆ˜**: ë”°ëœ»í•œ êµ­ë¬¼ê³¼ ì«„ê¹ƒí•œ ë©´ë°œì´ ì˜ ì–´ìš¸ë¦¬ëŠ” ìŒì‹ì…ë‹ˆë‹¤.\n",
      "5. **ìˆ˜ì œë¹„**: ë°€ê°€ë£¨ ë°˜ì£½ì„ ëœ¯ì–´ ë„£ì–´ ë§Œë“  êµ­ë¬¼ ìš”ë¦¬ë¡œ, ê°ìë‚˜ í˜¸ë°• ë“±ì„ ë„£ì–´ë„ ë§›ìˆìŠµë‹ˆë‹¤.\n",
      "6. **ì–´ë¬µíƒ•**: ì–´ë¬µê³¼ ë‹¤ì–‘í•œ ì±„ì†Œë¥¼ ë„£ì–´ ë“ì¸ êµ­ë¬¼ë¡œ ê°„ë‹¨í•˜ë©´ì„œë„ ë“ ë“ í•©ë‹ˆë‹¤.\n",
      "7. **í˜¸ë–¡**: ë‹¬ì½¤í•œ ì†ì´ ë“¤ì–´ê°„ ë”°ëœ»í•œ ê°„ì‹ìœ¼ë¡œ, ì¶”ìš´ ë‚ ì”¨ì— ê°„ì‹ìœ¼ë¡œ ì¢‹ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì™¸ì—ë„ ë”°ëœ»í•œ ì°¨ë‚˜ ì»¤í”¼ì™€ í•¨ê»˜ ì¦ê¸¸ ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ ë””ì €íŠ¸ë„ ì¢‹ìŠµë‹ˆë‹¤. ë”°ëœ»í•œ ìŒì‹ìœ¼ë¡œ ëª¸ì„ ë…¹ì´ë©° ê±´ê°•í•˜ê²Œ ê²¨ìš¸ì„ ë³´ë‚´ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "response = conversation_chain(\n",
    "    memory = memory,\n",
    "    query = 'ê°‘ìê¸° ë‚ ì”¨ê°€ ë„ˆë¬´ ì¶”ì›Œì¡Œì–´. ì´ë•Œ ë¨¹ì„ë§Œí•œ ìŒì‹ì„ ì¶”ì²œí•´ì¤˜'\n",
    ")\n",
    "print('ai : ', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai :  ì¶”ìš´ ë‚ ì”¨ì—ëŠ” ë”°ëœ»í•œ ë¶„ìœ„ê¸°ë¥¼ ë§Œë“¤ì–´ ì¤„ ìˆ˜ ìˆëŠ” ìŒì•…ì„ ë“£ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë‹¤ìŒì€ ì¶”ìš´ ë‚ ì”¨ì— ì–´ìš¸ë¦¬ëŠ” ìŒì•… ëª‡ ê°€ì§€ ì¶”ì²œì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **Norah Jones - \"Come Away With Me\"**: ë¶€ë“œëŸ½ê³  ê°ë¯¸ë¡œìš´ ëª©ì†Œë¦¬ê°€ ë§ˆìŒì„ í¸ì•ˆí•˜ê²Œ í•´ì¤ë‹ˆë‹¤.\n",
      "2. **Adele - \"Someone Like You\"**: ê°ì„±ì ì¸ ë°œë¼ë“œë¡œ, ì°¨ë¶„í•œ ì‹œê°„ì„ ë³´ë‚´ê¸°ì— ì¢‹ìŠµë‹ˆë‹¤.\n",
      "3. **Frank Sinatra - \"The Way You Look Tonight\"**: í´ë˜ì‹í•œ ì¬ì¦ˆ ê³¡ìœ¼ë¡œ, ë”°ëœ»í•œ ëŠë‚Œì„ ì¤ë‹ˆë‹¤.\n",
      "4. **Ed Sheeran - \"Perfect\"**: ë¡œë§¨í‹±í•œ ë¶„ìœ„ê¸°ì˜ ê³¡ìœ¼ë¡œ, ì¶”ìš´ ë‚ ì”¨ì— ì˜ ì–´ìš¸ë¦½ë‹ˆë‹¤.\n",
      "5. **Sara Bareilles - \"Winter Song\"**: ê²¨ìš¸ì˜ ë¶„ìœ„ê¸°ë¥¼ ì˜ ë‹´ì•„ë‚¸ ê³¡ì…ë‹ˆë‹¤.\n",
      "6. **Vivaldi - \"Winter\" from The Four Seasons**: í´ë˜ì‹ ìŒì•…ìœ¼ë¡œ, ê²¨ìš¸ì˜ ì°¨ê°€ìš´ ì•„ë¦„ë‹¤ì›€ì„ ëŠë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "7. **Bing Crosby - \"White Christmas\"**: ê²¨ìš¸ í•˜ë©´ ë– ì˜¤ë¥´ëŠ” í´ë˜ì‹í•œ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ ê³¡ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ìŒì•…ë“¤ì„ ë“¤ìœ¼ë©° ë”°ëœ»í•œ ìŒë£Œì™€ í•¨ê»˜ í¸ì•ˆí•œ ì‹œê°„ì„ ë³´ë‚´ë³´ì„¸ìš”. ìŒì•…ì´ ì£¼ëŠ” ë”°ëœ»í•¨ì´ ì¶”ìš´ ë‚ ì”¨ë¥¼ ìŠê²Œ í•´ì¤„ ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = conversation_chain(\n",
    "    memory = memory,\n",
    "    query = 'ê°‘ìê¸° ë‚ ì”¨ê°€ ë„ˆë¬´ ì¶”ì›Œì¡Œì–´. ì´ë•Œ ë“¤ì„ë§Œí•œ ìŒì•… ì¶”ì²œí•´ì¤˜'\n",
    ")\n",
    "print('ai : ', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai :  ì¶”ìš´ ë‚ ì”¨ì— ì–´ìš¸ë¦¬ëŠ” ë”°ëœ»í•œ ë¶„ìœ„ê¸°ì˜ í•œêµ­ ìŒì•…ì„ ì¶”ì²œí•´ë“œë¦´ê²Œìš”:\n",
      "\n",
      "1. **ê¹€ê´‘ì„ - \"ì´ë“±ë³‘ì˜ í¸ì§€\"**: ê°ì„±ì ì¸ ë©œë¡œë””ì™€ ê°€ì‚¬ê°€ ë§ˆìŒì„ ë”°ëœ»í•˜ê²Œ í•´ì¤ë‹ˆë‹¤.\n",
      "2. **ì•„ì´ìœ  - \"ë°¤í¸ì§€\"**: ë¶€ë“œëŸ¬ìš´ ëª©ì†Œë¦¬ì™€ ê°ë¯¸ë¡œìš´ ë©œë¡œë””ê°€ ì˜ ì–´ìš°ëŸ¬ì§„ ê³¡ì…ë‹ˆë‹¤.\n",
      "3. **í´í‚´ - \"ëª¨ë“  ë‚ , ëª¨ë“  ìˆœê°„\"**: ì‚¬ë‘ìŠ¤ëŸ¬ìš´ ê°€ì‚¬ì™€ ë©œë¡œë””ë¡œ ë§ˆìŒì„ ë…¹ì—¬ì¤ë‹ˆë‹¤.\n",
      "4. **ì„±ì‹œê²½ - \"ë„ˆì˜ ëª¨ë“  ìˆœê°„\"**: ê°ë¯¸ë¡œìš´ ë°œë¼ë“œë¡œ, ì°¨ë¶„í•œ ì‹œê°„ì„ ë³´ë‚´ê¸°ì— ì¢‹ìŠµë‹ˆë‹¤.\n",
      "5. **ì–´ë°˜ìì¹´íŒŒ - \"ê·¸ë•Œì˜ ë‚˜, ê·¸ë•Œì˜ ìš°ë¦¬\"**: ë”°ëœ»í•œ ê°ì„±ì„ ëŠë‚„ ìˆ˜ ìˆëŠ” ê³¡ì…ë‹ˆë‹¤.\n",
      "6. **ë°±ì˜ˆë¦° - \"Square (2017)\"**: ì”ì”í•œ ë©œë¡œë””ì™€ ë…íŠ¹í•œ ëª©ì†Œë¦¬ê°€ ë§¤ë ¥ì ì¸ ê³¡ì…ë‹ˆë‹¤.\n",
      "7. **ì´ë¬¸ì„¸ - \"ì˜›ì‚¬ë‘\"**: í´ë˜ì‹í•œ ë°œë¼ë“œë¡œ, ì¶”ì–µì„ ë– ì˜¬ë¦¬ê²Œ í•˜ëŠ” ê³¡ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ê³¡ë“¤ì„ ë“¤ìœ¼ë©° ë”°ëœ»í•œ ì°¨ í•œ ì”ê³¼ í•¨ê»˜ í¬ê·¼í•œ ì‹œê°„ì„ ë³´ë‚´ë³´ì„¸ìš”. ìŒì•…ì´ ì£¼ëŠ” ë”°ëœ»í•¨ì´ ì¶”ìš´ ë‚ ì”¨ë¥¼ ìŠê²Œ í•´ì¤„ ê²ƒì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = conversation_chain(\n",
    "    memory = memory,\n",
    "    query = 'ê°‘ìê¸° ë‚ ì”¨ê°€ ë„ˆë¬´ ì¶”ì›Œì¡Œì–´. ì´ë•Œ ë“¤ì„ë§Œí•œ í•œêµ­ìŒì•… ì¶”ì²œí•´ì¤˜'\n",
    ")\n",
    "print('ai : ', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai :  ì£„ì†¡í•˜ì§€ë§Œ, ì´ì „ì— ìŒì‹ì— ëŒ€í•œ ì¶”ì²œì„ ë“œë¦° ì ì€ ì—†ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì¶”ìš´ ë‚ ì”¨ì— ì–´ìš¸ë¦¬ëŠ” ìŒì‹ì„ ì¶”ì²œí•´ë“œë¦´ê¹Œìš”? ë”°ëœ»í•œ êµ­ë¬¼ ìš”ë¦¬ë‚˜ ëœ¨ê±°ìš´ ìŒë£Œê°€ ì¢‹ì„ ê²ƒ ê°™ì€ë°ìš”. ì˜ˆë¥¼ ë“¤ì–´, ê¹€ì¹˜ì°Œê°œ, ëœì¥ì°Œê°œ, ë–¡êµ­ ê°™ì€ í•œêµ­ ì „í†µ ìŒì‹ì´ë‚˜ ë”°ëœ»í•œ ì°¨ë‚˜ í•«ì´ˆì½” ê°™ì€ ìŒë£Œë¥¼ ì¶”ì²œë“œë¦½ë‹ˆë‹¤. ë„ì›€ì´ í•„ìš”í•˜ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "response = conversation_chain(\n",
    "    memory = memory,\n",
    "    query = 'ì•„ê¹Œ ì¶”ì²œí•´ì¤€ ìŒì‹ì´ ë­ì˜€ì§€?'\n",
    ")\n",
    "print('ai : ', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai :  ì•„ê¹Œ ì¶”ì²œí•´ë“œë¦° ìŒì•…ì€ ì¶”ìš´ ë‚ ì”¨ì— ì–´ìš¸ë¦¬ëŠ” ë”°ëœ»í•œ ë¶„ìœ„ê¸°ì˜ í•œêµ­ ìŒì•…ë“¤ì´ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€ë“œë¦¬ë©´:\n",
      "\n",
      "1. ê¹€ê´‘ì„ - \"ì´ë“±ë³‘ì˜ í¸ì§€\"\n",
      "2. ì•„ì´ìœ  - \"ë°¤í¸ì§€\"\n",
      "3. í´í‚´ - \"ëª¨ë“  ë‚ , ëª¨ë“  ìˆœê°„\"\n",
      "4. ì„±ì‹œê²½ - \"ë„ˆì˜ ëª¨ë“  ìˆœê°„\"\n",
      "5. ì–´ë°˜ìì¹´íŒŒ - \"ê·¸ë•Œì˜ ë‚˜, ê·¸ë•Œì˜ ìš°ë¦¬\"\n",
      "6. ë°±ì˜ˆë¦° - \"Square (2017)\"\n",
      "7. ì´ë¬¸ì„¸ - \"ì˜›ì‚¬ë‘\"\n",
      "\n",
      "ì´ ê³¡ë“¤ì´ ì¶”ìš´ ë‚ ì”¨ì— ë”°ëœ»í•œ ê°ì„±ì„ ëŠë¼ê²Œ í•´ì¤„ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”.\n"
     ]
    }
   ],
   "source": [
    "response = conversation_chain(\n",
    "    memory = memory,\n",
    "    query = 'ì•„ê¹Œ ì¶”ì²œí•´ì¤€ ìŒì•…ì´ ë­ì˜€ì§€?'\n",
    ")\n",
    "print('ai : ', response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model = 'gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RMARKET\\AppData\\Local\\Temp\\ipykernel_17708\\2976805407.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm = llm,\n",
    "    max_token_limit=200,\n",
    "    return_messages = True\n",
    ")\n",
    "# ëŒ€í™”ë‚´ìš©ì„ ìš”ì•½í•´ì„œ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì´ ì‹ë‹¹ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ë©”ë‰´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì´ ì‹ë‹¹ì—ì„œ ê°€ì¥ ì¸ê¸° ìˆëŠ” ë©”ë‰´ëŠ” ë¶ˆê³ ê¸° ì •ì‹, í•´ë¬¼íŒŒì „, ë¹„ë¹”ë°¥, ê·¸ë¦¬ê³  ê°ìíƒ•ì…ë‹ˆë‹¤. íŠ¹íˆ ë¶ˆê³ ê¸°ëŠ” ë‹¬ì½¤í•˜ê³  ì§­ì§¤í•œ ë§›ìœ¼ë¡œ ì™¸êµ­ì¸ ì†ë‹˜ë“¤ì—ê²Œë„ í° ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì±„ì‹ì£¼ì˜ìë¥¼ ìœ„í•œ ë©”ë‰´ê°€ ì œê³µë˜ë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë„¤, ì±„ì‹ì£¼ì˜ìë¥¼ ìœ„í•œ ë©”ë‰´ë¡œ ì±„ì†Œ ë¹„ë¹”ë°¥, ë‘ë¶€êµ¬ì´, ì•¼ì±„ì „, ê·¸ë¦¬ê³  ë‚˜ë¬¼ ë°˜ì°¬ ì„¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‹ ì„ í•œ ì œì²  ì±„ì†Œë¡œ ë§Œë“¤ì–´ì ¸ ê±´ê°•í•˜ê³  ë§›ìˆëŠ” ì‹ì‚¬ë¥¼ ì¦ê¸°ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì–´ë¦°ì´ë¥¼ ìœ„í•œ ë©”ë‰´ë„ ìˆë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ë„¤, ì–´ë¦°ì´ë¥¼ ìœ„í•œ ë©”ë‰´ë¡œ ë¯¸ë‹ˆ ê¹€ë°¥, ë–¡ë³¶ì´, ê·¸ë¦¬ê³  ë‹¬ì½¤í•œ ê°„ì¥ ì¹˜í‚¨ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ì´ë“¤ì´ ì¢‹ì•„í•  ë§Œí•œ ë§›ê³¼ ê±´ê°•ì„ ê³ ë ¤í•œ ìš”ë¦¬ë“¤ì…ë‹ˆë‹¤.\"\n",
    "    },\n",
    ")\n",
    "memory.save_context(\n",
    "    inputs={\"human\": \"ì´ ì‹ë‹¹ì€ ì–´ë–¤ ë¶„ìœ„ê¸°ë¥¼ ê°€ì§€ê³  ìˆë‚˜ìš”?\"},\n",
    "    outputs={\n",
    "        \"ai\": \"ì´ ì‹ë‹¹ì€ í•œì˜¥ ìŠ¤íƒ€ì¼ì˜ ì¸í…Œë¦¬ì–´ë¡œ ì „í†µì ì¸ í•œêµ­ì˜ ë¶„ìœ„ê¸°ë¥¼ ëŠë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ëœ»í•˜ê³  í¸ì•ˆí•œ ì¡°ëª…ê³¼ í˜„ëŒ€ì ì¸ ë””ìì¸ì´ ì¡°í™”ë¥¼ ì´ë£¨ì–´ ê°€ì¡± ë‹¨ìœ„ ì†ë‹˜ë¿ë§Œ ì•„ë‹ˆë¼ ì—°ì¸ë“¤ì˜ ë°ì´íŠ¸ ì¥ì†Œë¡œë„ ì¸ê¸°ê°€ ë§ìŠµë‹ˆë‹¤.\"\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='The human asks about the most popular menu items at the restaurant. The AI responds that the most popular items are bulgogi set, seafood pancake, bibimbap, and potato soup, noting that bulgogi is particularly popular among foreign guests due to its sweet and savory flavor. The human then inquires if there are menu options for vegetarians, to which the AI replies that vegetarian dishes include vegetable bibimbap, grilled tofu, vegetable pancakes, and a set of seasonal vegetable side dishes, all made with fresh, seasonal ingredients for a healthy and delicious meal.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì–´ë¦°ì´ë¥¼ ìœ„í•œ ë©”ë‰´ë„ ìˆë‚˜ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ë„¤, ì–´ë¦°ì´ë¥¼ ìœ„í•œ ë©”ë‰´ë¡œ ë¯¸ë‹ˆ ê¹€ë°¥, ë–¡ë³¶ì´, ê·¸ë¦¬ê³  ë‹¬ì½¤í•œ ê°„ì¥ ì¹˜í‚¨ì„ ì¤€ë¹„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì•„ì´ë“¤ì´ ì¢‹ì•„í•  ë§Œí•œ ë§›ê³¼ ê±´ê°•ì„ ê³ ë ¤í•œ ìš”ë¦¬ë“¤ì…ë‹ˆë‹¤.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='ì´ ì‹ë‹¹ì€ ì–´ë–¤ ë¶„ìœ„ê¸°ë¥¼ ê°€ì§€ê³  ìˆë‚˜ìš”?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='ì´ ì‹ë‹¹ì€ í•œì˜¥ ìŠ¤íƒ€ì¼ì˜ ì¸í…Œë¦¬ì–´ë¡œ ì „í†µì ì¸ í•œêµ­ì˜ ë¶„ìœ„ê¸°ë¥¼ ëŠë‚„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë”°ëœ»í•˜ê³  í¸ì•ˆí•œ ì¡°ëª…ê³¼ í˜„ëŒ€ì ì¸ ë””ìì¸ì´ ì¡°í™”ë¥¼ ì´ë£¨ì–´ ê°€ì¡± ë‹¨ìœ„ ì†ë‹˜ë¿ë§Œ ì•„ë‹ˆë¼ ì—°ì¸ë“¤ì˜ ë°ì´íŠ¸ ì¥ì†Œë¡œë„ ì¸ê¸°ê°€ ë§ìŠµë‹ˆë‹¤.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The human asks about the most popular menu items at the restaurant. The AI responds that the most popular items are bulgogi set, seafood pancake, bibimbap, and potato soup, noting that bulgogi is particularly popular among foreign guests due to its sweet and savory flavor. The human then inquires if there are menu options for vegetarians, to which the AI replies that vegetarian dishes include vegetable bibimbap, grilled tofu, vegetable pancakes, and a set of seasonal vegetable side dishes, all made with fresh, seasonal ingredients for a healthy and delicious meal.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})['history'][0].content # ëŒ€í™”ë‚´ìš©ì„ ìš”ì•½ë³¸ìœ¼ë¡œ ì €ì¥ (30ê°œ ì´ìƒì€ ìš”ì•½ë³¸ìœ¼ë¡œ ì €ì¥)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
