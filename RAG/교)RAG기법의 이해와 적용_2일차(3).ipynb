{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸŒ¼ RAGê¸°ë²•ì˜ ì´í•´ì™€ ì ìš©(3) - 2ì°¨ì‹œ(24.11.29)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith ì¶”ì ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[í”„ë¡œì íŠ¸ëª…]\n",
      "CLASS\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote import logging\n",
    "logging.langsmith('CLASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì†ë„ë¥¼ ë” ë¹ ë¥´ê²Œ\n",
    "prompt = PromptTemplate.from_template('{country}ì— ëŒ€í•´ 300ì ë‚´ì™¸ë¡œ ìš”ì•½í•´ì„œ ì„¤ëª…í•´ì¤˜')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì€ ë™ì•„ì‹œì•„ì— ìœ„ì¹˜í•œ í•œë°˜ë„ì˜ ë‚¨ìª½ ë¶€ë¶„ì„ ì°¨ì§€í•˜ê³  ìˆëŠ” ë‚˜ë¼ë¡œ, ê³µì‹ ëª…ì¹­ì€ ëŒ€í•œë¯¼êµ­ì…ë‹ˆë‹¤. ì„œìš¸ì´ ìˆ˜ë„ì´ë©°, ì•½ 5ì²œë§Œ ëª…ì˜ ì¸êµ¬ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì€ ê²½ì œì ìœ¼ë¡œ ê³ ë„ë¡œ ë°œì „í•œ êµ­ê°€ë¡œ, ê¸°ìˆ ê³¼ í˜ì‹ ì˜ ì¤‘ì‹¬ì§€ë¡œ ì•Œë ¤ì ¸ ìˆìœ¼ë©°, ì‚¼ì„±, í˜„ëŒ€ì™€ ê°™ì€ ê¸€ë¡œë²Œ ê¸°ì—…ë“¤ì´ ë³¸ì‚¬ë¥¼ ë‘ê³  ìˆìŠµë‹ˆë‹¤. ë˜í•œ, K-íŒ, ë“œë¼ë§ˆ, ì˜í™” ë“± í•œë¥˜ ë¬¸í™”ê°€ ì „ ì„¸ê³„ì ìœ¼ë¡œ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤. í•œêµ­ì€ ë¯¼ì£¼ì£¼ì˜ ì²´ì œë¥¼ ê°–ì¶”ê³  ìˆìœ¼ë©°, êµìœ¡ì—´ì´ ë†’ê³  ì˜ë£Œ ì‹œìŠ¤í…œì´ ì˜ ë°œë‹¬ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì—­ì‚¬ì ìœ¼ë¡œëŠ” ê¸´ ì„¸ì›” ë™ì•ˆ ì¤‘êµ­ê³¼ ì¼ë³¸ì˜ ì˜í–¥ì„ ë°›ì•˜ìœ¼ë©°, í˜„ì¬ëŠ” ë¶„ë‹¨êµ­ê°€ë¡œì„œ ë¶í•œê³¼ì˜ ê´€ê³„ê°€ ì¤‘ìš”í•œ ì´ìŠˆ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 3.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country' : 'í•œêµ­'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_llm_cache\n",
    "from langchain.cache import InMemoryCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "# ì´ë¯¸ ì²˜ë¦¬ëœ ìš”ì²­ê³¼ ì‘ë‹µ ë°ì´í„°ë¥¼ ë©”ëª¨ë¦¬ì— ì €ì¥ -> ë™ì¼í•œ ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ê²°ê³¼ë¥¼ ì¬ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì€ ë™ì•„ì‹œì•„ì— ìœ„ì¹˜í•œ ë°˜ë„ êµ­ê°€ë¡œ, ê³µì‹ì ìœ¼ë¡œëŠ” ëŒ€í•œë¯¼êµ­ì´ë¼ ë¶ˆë¦½ë‹ˆë‹¤. í•œë°˜ë„ì˜ ë‚¨ìª½ì„ ì°¨ì§€í•˜ê³  ìˆìœ¼ë©°, ë¶ìª½ìœ¼ë¡œëŠ” ë¶í•œê³¼ ì ‘ê²½ì„ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤. ìˆ˜ë„ëŠ” ì„œìš¸ì´ë©°, ì¸êµ¬ëŠ” ì•½ 5ì²œë§Œ ëª…ì…ë‹ˆë‹¤. í•œêµ­ì€ ì²¨ë‹¨ ê¸°ìˆ ê³¼ ë¬¸í™”, íŠ¹íˆ K-íŒ, ë“œë¼ë§ˆ, ì˜í™” ë“±ìœ¼ë¡œ ì„¸ê³„ì ìœ¼ë¡œ ì¸ê¸°ë¥¼ ëŒê³  ìˆìŠµë‹ˆë‹¤. ê²½ì œëŠ” ìë™ì°¨, ì „ìì œí’ˆ, ì¡°ì„ ì—… ë“± ë‹¤ì–‘í•œ ì‚°ì—…ì—ì„œ ê°•ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤. ë˜í•œ, í•œêµ­ì€ ë…íŠ¹í•œ ì—­ì‚¬ì™€ ì „í†µì„ ì§€ë‹Œ êµ­ê°€ë¡œ, í•œê¸€ì´ë¼ëŠ” ë…ì°½ì ì¸ ë¬¸ìë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 1.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country' : 'í•œêµ­'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.cache import SQLiteCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('cache'):\n",
    "    os.makedirs('cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(SQLiteCache(database_path = 'cache/llm_cache.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìºë‚˜ë‹¤ëŠ” ë¶ì•„ë©”ë¦¬ì¹´ ëŒ€ë¥™ì˜ ë¶ë¶€ì— ìœ„ì¹˜í•œ ë‚˜ë¼ë¡œ, ì„¸ê³„ì—ì„œ ë‘ ë²ˆì§¸ë¡œ í° ë©´ì ì„ ìë‘í•©ë‹ˆë‹¤. ìˆ˜ë„ëŠ” ì˜¤íƒ€ì™€ì´ë©°, ì£¼ìš” ë„ì‹œë¡œëŠ” í† ë¡ í† , ë°´ì¿ ë²„, ëª¬íŠ¸ë¦¬ì˜¬ ë“±ì´ ìˆìŠµë‹ˆë‹¤. ê³µì‹ ì–¸ì–´ëŠ” ì˜ì–´ì™€ í”„ë‘ìŠ¤ì–´ì´ë©°, ë‹¤ë¬¸í™” ì‚¬íšŒë¡œì„œ ë‹¤ì–‘í•œ ì¸ì¢…ê³¼ ë¬¸í™”ê°€ ê³µì¡´í•©ë‹ˆë‹¤. ìì—° ê²½ê´€ì´ ë›°ì–´ë‚˜ë©°, ë¡œí‚¤ ì‚°ë§¥ê³¼ ë‚˜ì´ì•„ê°€ë¼ í­í¬ì™€ ê°™ì€ ê´€ê´‘ ëª…ì†Œê°€ ìœ ëª…í•©ë‹ˆë‹¤. ì •ì¹˜ì ìœ¼ë¡œëŠ” ì…í—Œêµ°ì£¼ì œì™€ ì—°ë°©ì œë¥¼ ì±„íƒí•˜ê³  ìˆìœ¼ë©°, ê²½ì œëŠ” ìì› ê°œë°œê³¼ ë¬´ì—­, ì„œë¹„ìŠ¤ ì‚°ì—…ì— ê¸°ë°˜ì„ ë‘ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 11.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country' : 'ìºë‚˜ë‹¤'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜êµ­ì€ ì„œìœ ëŸ½ì— ìœ„ì¹˜í•œ ì„¬ë‚˜ë¼ì´ë©°, ì‰ê¸€ëœë“œ, ìŠ¤ì½”í‹€ëœë“œ, ì›¨ì¼ìŠ¤, ë¶ì•„ì¼ëœë“œë¡œ êµ¬ì„±ëœ ì—°í•© ì™•êµ­ì…ë‹ˆë‹¤. ìˆ˜ë„ëŠ” ëŸ°ë˜ìœ¼ë¡œ, ì„¸ê³„ì ì¸ ê¸ˆìœµ, ë¬¸í™”, ì—­ì‚¬ ì¤‘ì‹¬ì§€ì…ë‹ˆë‹¤. ì˜êµ­ì€ ì…í—Œêµ°ì£¼ì œë¡œ, í˜„ì¬ì˜ êµ­ì™•ì€ ì°°ìŠ¤ 3ì„¸ì…ë‹ˆë‹¤. ì‚°ì—…í˜ëª…ì˜ ë°œìƒì§€ë¡œì„œ ê²½ì œ ë°œì „ì˜ ì„ ë‘ì£¼ìì˜€ìœ¼ë©°, í˜„ì¬ë„ ê²½ì œ, ì •ì¹˜, ë¬¸í™” ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ êµ­ì œì  ì˜í–¥ë ¥ì„ í–‰ì‚¬í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ëª…ì†Œë¡œëŠ” ëŸ°ë˜ì˜ ë¹…ë²¤, íƒ€ì›Œë¸Œë¦¬ì§€, ì—ë“ ë²„ëŸ¬ ì„± ë“±ì´ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ì˜êµ­ì€ í”„ë¦¬ë¯¸ì–´ ë¦¬ê·¸ë¡œ ìœ ëª…í•œ ì¶•êµ¬ì˜ ë³¸ê³ ì¥ì´ê¸°ë„ í•©ë‹ˆë‹¤.\n",
      "CPU times: total: 109 ms\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "response = chain.invoke({'country' : 'ì˜êµ­'})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbê°€ ì–´ë–»ê²Œ ì €ì¥ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = 'cache/llm_cache.db'\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables [('full_llm_cache',), ('full_md5_llm_cache',)]\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT name FROM  sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print('Tables', tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "cache contesnts:\n",
      "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"\\\\uce90\\\\ub098\\\\ub2e4\\\\uc5d0 \\\\ub300\\\\ud574 300\\\\uc790 \\\\ub0b4\\\\uc678\\\\ub85c \\\\uc694\\\\uc57d\\\\ud574\\\\uc11c \\\\uc124\\\\uba85\\\\ud574\\\\uc918\", \"type\": \"human\"}}]', '{\"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"max_retries\": 2, \"model_name\": \"gpt-4o\", \"n\": 1, \"openai_api_key\": {\"id\": [\"OPENAI_API_KEY\"], \"lc\": 1, \"type\": \"secret\"}, \"temperature\": 0.7}, \"lc\": 1, \"name\": \"ChatOpenAI\", \"type\": \"constructor\"}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output\", \"ChatGeneration\"], \"kwargs\": {\"text\": \"\\\\uce90\\\\ub098\\\\ub2e4\\\\ub294 \\\\ubd81\\\\uc544\\\\uba54\\\\ub9ac\\\\uce74 \\\\ub300\\\\ub959\\\\uc758 \\\\ubd81\\\\ubd80\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\ub098\\\\ub77c\\\\ub85c, \\\\uc138\\\\uacc4\\\\uc5d0\\\\uc11c \\\\ub450 \\\\ubc88\\\\uc9f8\\\\ub85c \\\\ud070 \\\\uba74\\\\uc801\\\\uc744 \\\\uc790\\\\ub791\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\uc624\\\\ud0c0\\\\uc640\\\\uc774\\\\uba70, \\\\uc8fc\\\\uc694 \\\\ub3c4\\\\uc2dc\\\\ub85c\\\\ub294 \\\\ud1a0\\\\ub860\\\\ud1a0, \\\\ubc34\\\\ucfe0\\\\ubc84, \\\\ubaac\\\\ud2b8\\\\ub9ac\\\\uc62c \\\\ub4f1\\\\uc774 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uacf5\\\\uc2dd \\\\uc5b8\\\\uc5b4\\\\ub294 \\\\uc601\\\\uc5b4\\\\uc640 \\\\ud504\\\\ub791\\\\uc2a4\\\\uc5b4\\\\uc774\\\\uba70, \\\\ub2e4\\\\ubb38\\\\ud654 \\\\uc0ac\\\\ud68c\\\\ub85c\\\\uc11c \\\\ub2e4\\\\uc591\\\\ud55c \\\\uc778\\\\uc885\\\\uacfc \\\\ubb38\\\\ud654\\\\uac00 \\\\uacf5\\\\uc874\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc790\\\\uc5f0 \\\\uacbd\\\\uad00\\\\uc774 \\\\ub6f0\\\\uc5b4\\\\ub098\\\\uba70, \\\\ub85c\\\\ud0a4 \\\\uc0b0\\\\ub9e5\\\\uacfc \\\\ub098\\\\uc774\\\\uc544\\\\uac00\\\\ub77c \\\\ud3ed\\\\ud3ec\\\\uc640 \\\\uac19\\\\uc740 \\\\uad00\\\\uad11 \\\\uba85\\\\uc18c\\\\uac00 \\\\uc720\\\\uba85\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc815\\\\uce58\\\\uc801\\\\uc73c\\\\ub85c\\\\ub294 \\\\uc785\\\\ud5cc\\\\uad70\\\\uc8fc\\\\uc81c\\\\uc640 \\\\uc5f0\\\\ubc29\\\\uc81c\\\\ub97c \\\\ucc44\\\\ud0dd\\\\ud558\\\\uace0 \\\\uc788\\\\uc73c\\\\uba70, \\\\uacbd\\\\uc81c\\\\ub294 \\\\uc790\\\\uc6d0 \\\\uac1c\\\\ubc1c\\\\uacfc \\\\ubb34\\\\uc5ed, \\\\uc11c\\\\ube44\\\\uc2a4 \\\\uc0b0\\\\uc5c5\\\\uc5d0 \\\\uae30\\\\ubc18\\\\uc744 \\\\ub450\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"generation_info\": {\"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ChatGeneration\", \"message\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"AIMessage\"], \"kwargs\": {\"content\": \"\\\\uce90\\\\ub098\\\\ub2e4\\\\ub294 \\\\ubd81\\\\uc544\\\\uba54\\\\ub9ac\\\\uce74 \\\\ub300\\\\ub959\\\\uc758 \\\\ubd81\\\\ubd80\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\ub098\\\\ub77c\\\\ub85c, \\\\uc138\\\\uacc4\\\\uc5d0\\\\uc11c \\\\ub450 \\\\ubc88\\\\uc9f8\\\\ub85c \\\\ud070 \\\\uba74\\\\uc801\\\\uc744 \\\\uc790\\\\ub791\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\uc624\\\\ud0c0\\\\uc640\\\\uc774\\\\uba70, \\\\uc8fc\\\\uc694 \\\\ub3c4\\\\uc2dc\\\\ub85c\\\\ub294 \\\\ud1a0\\\\ub860\\\\ud1a0, \\\\ubc34\\\\ucfe0\\\\ubc84, \\\\ubaac\\\\ud2b8\\\\ub9ac\\\\uc62c \\\\ub4f1\\\\uc774 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uacf5\\\\uc2dd \\\\uc5b8\\\\uc5b4\\\\ub294 \\\\uc601\\\\uc5b4\\\\uc640 \\\\ud504\\\\ub791\\\\uc2a4\\\\uc5b4\\\\uc774\\\\uba70, \\\\ub2e4\\\\ubb38\\\\ud654 \\\\uc0ac\\\\ud68c\\\\ub85c\\\\uc11c \\\\ub2e4\\\\uc591\\\\ud55c \\\\uc778\\\\uc885\\\\uacfc \\\\ubb38\\\\ud654\\\\uac00 \\\\uacf5\\\\uc874\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc790\\\\uc5f0 \\\\uacbd\\\\uad00\\\\uc774 \\\\ub6f0\\\\uc5b4\\\\ub098\\\\uba70, \\\\ub85c\\\\ud0a4 \\\\uc0b0\\\\ub9e5\\\\uacfc \\\\ub098\\\\uc774\\\\uc544\\\\uac00\\\\ub77c \\\\ud3ed\\\\ud3ec\\\\uc640 \\\\uac19\\\\uc740 \\\\uad00\\\\uad11 \\\\uba85\\\\uc18c\\\\uac00 \\\\uc720\\\\uba85\\\\ud569\\\\ub2c8\\\\ub2e4. \\\\uc815\\\\uce58\\\\uc801\\\\uc73c\\\\ub85c\\\\ub294 \\\\uc785\\\\ud5cc\\\\uad70\\\\uc8fc\\\\uc81c\\\\uc640 \\\\uc5f0\\\\ubc29\\\\uc81c\\\\ub97c \\\\ucc44\\\\ud0dd\\\\ud558\\\\uace0 \\\\uc788\\\\uc73c\\\\uba70, \\\\uacbd\\\\uc81c\\\\ub294 \\\\uc790\\\\uc6d0 \\\\uac1c\\\\ubc1c\\\\uacfc \\\\ubb34\\\\uc5ed, \\\\uc11c\\\\ube44\\\\uc2a4 \\\\uc0b0\\\\uc5c5\\\\uc5d0 \\\\uae30\\\\ubc18\\\\uc744 \\\\ub450\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4.\", \"additional_kwargs\": {\"refusal\": null}, \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 152, \"prompt_tokens\": 23, \"total_tokens\": 175, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}, \"model_name\": \"gpt-4o-2024-08-06\", \"system_fingerprint\": \"fp_831e067d82\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"id\": \"run-05f98043-cbca-4e25-9db1-83d891aa109c-0\", \"usage_metadata\": {\"input_tokens\": 23, \"output_tokens\": 152, \"total_tokens\": 175, \"input_token_details\": {\"audio\": 0, \"cache_read\": 0}, \"output_token_details\": {\"audio\": 0, \"reasoning\": 0}}, \"tool_calls\": [], \"invalid_tool_calls\": []}}}}')\n",
      "('[{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"HumanMessage\"], \"kwargs\": {\"content\": \"\\\\uc601\\\\uad6d\\\\uc5d0 \\\\ub300\\\\ud574 300\\\\uc790 \\\\ub0b4\\\\uc678\\\\ub85c \\\\uc694\\\\uc57d\\\\ud574\\\\uc11c \\\\uc124\\\\uba85\\\\ud574\\\\uc918\", \"type\": \"human\"}}]', '{\"id\": [\"langchain\", \"chat_models\", \"openai\", \"ChatOpenAI\"], \"kwargs\": {\"max_retries\": 2, \"model_name\": \"gpt-4o\", \"n\": 1, \"openai_api_key\": {\"id\": [\"OPENAI_API_KEY\"], \"lc\": 1, \"type\": \"secret\"}, \"temperature\": 0.7}, \"lc\": 1, \"name\": \"ChatOpenAI\", \"type\": \"constructor\"}---[(\\'stop\\', None)]', 0, '{\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"output\", \"ChatGeneration\"], \"kwargs\": {\"text\": \"\\\\uc601\\\\uad6d\\\\uc740 \\\\uc11c\\\\uc720\\\\ub7fd\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\uc12c\\\\ub098\\\\ub77c\\\\uc774\\\\uba70, \\\\uc789\\\\uae00\\\\ub79c\\\\ub4dc, \\\\uc2a4\\\\ucf54\\\\ud2c0\\\\ub79c\\\\ub4dc, \\\\uc6e8\\\\uc77c\\\\uc2a4, \\\\ubd81\\\\uc544\\\\uc77c\\\\ub79c\\\\ub4dc\\\\ub85c \\\\uad6c\\\\uc131\\\\ub41c \\\\uc5f0\\\\ud569 \\\\uc655\\\\uad6d\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\ub7f0\\\\ub358\\\\uc73c\\\\ub85c, \\\\uc138\\\\uacc4\\\\uc801\\\\uc778 \\\\uae08\\\\uc735, \\\\ubb38\\\\ud654, \\\\uc5ed\\\\uc0ac \\\\uc911\\\\uc2ec\\\\uc9c0\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc601\\\\uad6d\\\\uc740 \\\\uc785\\\\ud5cc\\\\uad70\\\\uc8fc\\\\uc81c\\\\ub85c, \\\\ud604\\\\uc7ac\\\\uc758 \\\\uad6d\\\\uc655\\\\uc740 \\\\ucc30\\\\uc2a4 3\\\\uc138\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc0b0\\\\uc5c5\\\\ud601\\\\uba85\\\\uc758 \\\\ubc1c\\\\uc0c1\\\\uc9c0\\\\ub85c\\\\uc11c \\\\uacbd\\\\uc81c \\\\ubc1c\\\\uc804\\\\uc758 \\\\uc120\\\\ub450\\\\uc8fc\\\\uc790\\\\uc600\\\\uc73c\\\\uba70, \\\\ud604\\\\uc7ac\\\\ub3c4 \\\\uacbd\\\\uc81c, \\\\uc815\\\\uce58, \\\\ubb38\\\\ud654 \\\\ub4f1 \\\\ub2e4\\\\uc591\\\\ud55c \\\\ubd84\\\\uc57c\\\\uc5d0\\\\uc11c \\\\uad6d\\\\uc81c\\\\uc801 \\\\uc601\\\\ud5a5\\\\ub825\\\\uc744 \\\\ud589\\\\uc0ac\\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc8fc\\\\uc694 \\\\uba85\\\\uc18c\\\\ub85c\\\\ub294 \\\\ub7f0\\\\ub358\\\\uc758 \\\\ube45\\\\ubca4, \\\\ud0c0\\\\uc6cc\\\\ube0c\\\\ub9ac\\\\uc9c0, \\\\uc5d0\\\\ub4e0\\\\ubc84\\\\ub7ec \\\\uc131 \\\\ub4f1\\\\uc774 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\ub610\\\\ud55c, \\\\uc601\\\\uad6d\\\\uc740 \\\\ud504\\\\ub9ac\\\\ubbf8\\\\uc5b4 \\\\ub9ac\\\\uadf8\\\\ub85c \\\\uc720\\\\uba85\\\\ud55c \\\\ucd95\\\\uad6c\\\\uc758 \\\\ubcf8\\\\uace0\\\\uc7a5\\\\uc774\\\\uae30\\\\ub3c4 \\\\ud569\\\\ub2c8\\\\ub2e4.\", \"generation_info\": {\"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ChatGeneration\", \"message\": {\"lc\": 1, \"type\": \"constructor\", \"id\": [\"langchain\", \"schema\", \"messages\", \"AIMessage\"], \"kwargs\": {\"content\": \"\\\\uc601\\\\uad6d\\\\uc740 \\\\uc11c\\\\uc720\\\\ub7fd\\\\uc5d0 \\\\uc704\\\\uce58\\\\ud55c \\\\uc12c\\\\ub098\\\\ub77c\\\\uc774\\\\uba70, \\\\uc789\\\\uae00\\\\ub79c\\\\ub4dc, \\\\uc2a4\\\\ucf54\\\\ud2c0\\\\ub79c\\\\ub4dc, \\\\uc6e8\\\\uc77c\\\\uc2a4, \\\\ubd81\\\\uc544\\\\uc77c\\\\ub79c\\\\ub4dc\\\\ub85c \\\\uad6c\\\\uc131\\\\ub41c \\\\uc5f0\\\\ud569 \\\\uc655\\\\uad6d\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc218\\\\ub3c4\\\\ub294 \\\\ub7f0\\\\ub358\\\\uc73c\\\\ub85c, \\\\uc138\\\\uacc4\\\\uc801\\\\uc778 \\\\uae08\\\\uc735, \\\\ubb38\\\\ud654, \\\\uc5ed\\\\uc0ac \\\\uc911\\\\uc2ec\\\\uc9c0\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc601\\\\uad6d\\\\uc740 \\\\uc785\\\\ud5cc\\\\uad70\\\\uc8fc\\\\uc81c\\\\ub85c, \\\\ud604\\\\uc7ac\\\\uc758 \\\\uad6d\\\\uc655\\\\uc740 \\\\ucc30\\\\uc2a4 3\\\\uc138\\\\uc785\\\\ub2c8\\\\ub2e4. \\\\uc0b0\\\\uc5c5\\\\ud601\\\\uba85\\\\uc758 \\\\ubc1c\\\\uc0c1\\\\uc9c0\\\\ub85c\\\\uc11c \\\\uacbd\\\\uc81c \\\\ubc1c\\\\uc804\\\\uc758 \\\\uc120\\\\ub450\\\\uc8fc\\\\uc790\\\\uc600\\\\uc73c\\\\uba70, \\\\ud604\\\\uc7ac\\\\ub3c4 \\\\uacbd\\\\uc81c, \\\\uc815\\\\uce58, \\\\ubb38\\\\ud654 \\\\ub4f1 \\\\ub2e4\\\\uc591\\\\ud55c \\\\ubd84\\\\uc57c\\\\uc5d0\\\\uc11c \\\\uad6d\\\\uc81c\\\\uc801 \\\\uc601\\\\ud5a5\\\\ub825\\\\uc744 \\\\ud589\\\\uc0ac\\\\ud558\\\\uace0 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\uc8fc\\\\uc694 \\\\uba85\\\\uc18c\\\\ub85c\\\\ub294 \\\\ub7f0\\\\ub358\\\\uc758 \\\\ube45\\\\ubca4, \\\\ud0c0\\\\uc6cc\\\\ube0c\\\\ub9ac\\\\uc9c0, \\\\uc5d0\\\\ub4e0\\\\ubc84\\\\ub7ec \\\\uc131 \\\\ub4f1\\\\uc774 \\\\uc788\\\\uc2b5\\\\ub2c8\\\\ub2e4. \\\\ub610\\\\ud55c, \\\\uc601\\\\uad6d\\\\uc740 \\\\ud504\\\\ub9ac\\\\ubbf8\\\\uc5b4 \\\\ub9ac\\\\uadf8\\\\ub85c \\\\uc720\\\\uba85\\\\ud55c \\\\ucd95\\\\uad6c\\\\uc758 \\\\ubcf8\\\\uace0\\\\uc7a5\\\\uc774\\\\uae30\\\\ub3c4 \\\\ud569\\\\ub2c8\\\\ub2e4.\", \"additional_kwargs\": {\"refusal\": null}, \"response_metadata\": {\"token_usage\": {\"completion_tokens\": 169, \"prompt_tokens\": 23, \"total_tokens\": 192, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}, \"model_name\": \"gpt-4o-2024-08-06\", \"system_fingerprint\": \"fp_831e067d82\", \"finish_reason\": \"stop\", \"logprobs\": null}, \"type\": \"ai\", \"id\": \"run-27890d82-4083-4918-8a03-865e7f549be7-0\", \"usage_metadata\": {\"input_tokens\": 23, \"output_tokens\": 169, \"total_tokens\": 192, \"input_token_details\": {\"audio\": 0, \"cache_read\": 0}, \"output_token_details\": {\"audio\": 0, \"reasoning\": 0}}, \"tool_calls\": [], \"invalid_tool_calls\": []}}}}')\n"
     ]
    }
   ],
   "source": [
    "cursor.execute('SELECT * FROM full_llm_cache;')\n",
    "rows = cursor.fetchall()\n",
    "print('\\ncache contesnts:')\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close() # ë””ë¹„ë¥¼ ì˜ ì €ì¥í•˜ê¸° ìœ„í•´ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 26\n",
      "\tPrompt Tokens: 15\n",
      "\tCompletion Tokens: 11\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00014749999999999998\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 688 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke('ëŒ€í•œë¯¼êµ­ì— ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”')\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì‚¬ìš©ëœ í† í° ìˆ˜ : 25\n",
      "í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ëœ í† í° ìˆ˜ : 15\n",
      "ë‹µë³€ì— ì‚¬ìš©ëœ í† í° ìˆ˜ : 10\n",
      "í˜¸ì¶œì— ì²­êµ¬ëœ ê¸ˆì•¡(USD) : 0.0001375\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    result = llm.invoke('ê²¨ìš¸ì€ ì˜ì–´ë¡œ ë­ì•¼?')\n",
    "    print(f'ì´ ì‚¬ìš©ëœ í† í° ìˆ˜ : {cb.total_tokens}')\n",
    "    print(f'í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©ëœ í† í° ìˆ˜ : {cb.prompt_tokens}')\n",
    "    print(f'ë‹µë³€ì— ì‚¬ìš©ëœ í† í° ìˆ˜ : {cb.completion_tokens}')\n",
    "    print(f'í˜¸ì¶œì— ì²­êµ¬ëœ ê¸ˆì•¡(USD) : {cb.total_cost}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\RMARKET\\anaconda3\\envs\\langchain\\Lib\\site-packages\\~ydantic_core'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "# pip install -qU langchain-community arxiv pymupdf pypdf unstructured python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = './data/SPRi AI Brief_11ì›”í˜¸_ì‚°ì—…ë™í–¥_F.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”íƒ€ë°ì´í„°ë¥¼ ë³¼ ìˆ˜ ìˆê²Œ í•˜ëŠ” í•¨ìˆ˜\n",
    "# source, page, meta-dataë¥¼ ë¶ˆëŸ¬ì˜´\n",
    "def show_metadata(docs):\n",
    "    if docs:\n",
    "        print('[metadata]')\n",
    "        keys = []\n",
    "        for k in docs[0].metadata.keys():\n",
    "            keys.append(k)\n",
    "        print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metadata]\n",
      "['source', 'page']\n"
     ]
    }
   ],
   "source": [
    "show_metadata(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPRi AI Brief |  2024-11ì›”í˜¸\n",
      "8\n",
      "ë©”íƒ€, ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì²˜ë¦¬í•˜ëŠ” ì²« ë©€í‹°ëª¨ë‹¬ AI ëª¨ë¸ â€˜ë¼ë§ˆ 3.2â€™ ê³µê°œnë©”íƒ€ê°€ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ëª¨ë‘ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ê³¼ ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê²½ëŸ‰ ëª¨ë¸ì„ í¬í•¨í•˜ëŠ” ë¼ë§ˆ 3.2 ì‹œë¦¬ì¦ˆë¥¼ ê³µê°œnë¹„ì „ ê¸°ëŠ¥ì„ ê°–ì¶˜ ë¼ë§ˆ 3.2 90B ëª¨ë¸ì€ ë‹¤ì–‘í•œ ì´ë¯¸ì§€ ì¸ì‹ê³¼ ì‹œê°ì  ì´í•´ ì‘ì—…ì—ì„œ ì•¤ìŠ¤ë¡œí”½ì˜ â€˜í´ë¡œë“œ3-í•˜ì´ì¿ â€™ ë° ì˜¤í”ˆAIì˜ â€˜GPT-4o-ë¯¸ë‹ˆâ€™ì™€ ëŒ€ë“±í•œ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ ë³´ìœ \n",
      "KEY Contents\n",
      "Â£ë¼ë§ˆ 3.2 90B ëª¨ë¸, ì´ë¯¸ì§€ ì¸ì‹ê³¼ ì‹œê°ì  ì´í•´ì—ì„œ GPT-4o-ë¯¸\n"
     ]
    }
   ],
   "source": [
    "# í…ìŠ¤íŠ¸ ë¶€ë¶„ë§Œ ì¶œë ¥\n",
    "print(docs[10].page_content[:300]) # docs[pageë²ˆí˜¸]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ 11ì›”í˜¸\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:300]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ 11ì›”í˜¸\n",
      "â… . ì¸ê³µì§€ëŠ¥ ì‚°ì—… ë™í–¥ ë¸Œë¦¬í”„ 1. ì •ì±…/ë²•ì œ    â–¹ ë¯¸êµ­ ë¯¼ê¶Œìœ„ì›íšŒ, ì—°ë°©ì •ë¶€ì˜ ì–¼êµ´ì¸ì‹ ê¸°ìˆ  ì‚¬ìš©ì— ë”°ë¥¸ ë¯¼ê¶Œ ì˜í–¥ ë¶„ì„Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·1   â–¹ ë¯¸êµ­ ë°±ì•…ê´€ ì˜ˆì‚°ê´€ë¦¬êµ­, ì •ë¶€ì˜ ì±…ì„ ìˆëŠ” AI ì¡°ë‹¬ì„ ìœ„í•œ ì§€ì¹¨ ë°œí‘œÂ·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·2   â–¹ ìœ ë¡œí´, ë²• ì§‘í–‰ì—ì„œ AIì˜ ì´ì ê³¼ ê³¼ì œë¥¼ ë‹¤ë£¬ ë³´ê³ ì„œ ë°œê°„Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·3   â–¹ OECD, ê³µê³µ ë¶€ë¬¸ì˜ AI ë„ì…ì„ ìœ„í•œ G7 íˆ´í‚· \n"
     ]
    }
   ],
   "source": [
    "print(docs[1].page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPowerPointLoader\n",
    "\n",
    "loader = UnstructuredPowerPointLoader('./data/RAG(ì§€ì‹ ê²€ìƒ‰ ë° ìƒì„± ê¸°ë²•)ê¸°ë²• ì ìš©_2ì¼ì°¨.pptx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': './data/RAG(ì§€ì‹ ê²€ìƒ‰ ë° ìƒì„± ê¸°ë²•)ê¸°ë²• ì ìš©_2ì¼ì°¨.pptx'}, page_content='RAG(ì§€ì‹ ê²€ìƒ‰ ë° ìƒì„± ê¸°ë²•) ì ìš©\\n\\nDay 02\\n\\nê°•ì˜ì : ê¹€ìˆ˜ë¹ˆ\\n\\n\\n\\n1\\n\\n2\\n\\n3\\n\\nContents\\n\\nRAG\\n\\në²¡í„° DB\\n\\nLangchain\\n\\n\\n\\n1\\n\\n2\\n\\n3\\n\\n3\\n\\nLangChain\\n\\në­ì²´ì¸?\\n\\n- ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì„ í™œìš©í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‰½ê²Œ ê°œë°œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” í”„ë ˆì„ì›Œí¬\\n\\nLLMê³¼ ë„êµ¬ ì—°ê²° : Vecor DB, API, íŒŒì¼ ë“±ê³¼ í†µí•©\\n\\nì‘ì—… ìë™í™” : ìë™í™”ëœ ì›Œí¬í”Œë¡œìš° êµ¬í˜„ ì§€ì›\\n\\nê²€ìƒ‰ ë° ìƒì„± ê¸°ëŠ¥ : LLMê³¼ ê²€ìƒ‰ ê¸°ë°˜ ì‹œìŠ¤í…œì„ ê²°í•©í•´ ì‘ë‹µì˜ í’ˆì§ˆ í–¥ìƒ\\n\\n\\n\\n3\\n\\nLangChain\\n\\nê¸°ëŠ¥\\n\\ní”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­, ì†Œìˆ˜ì˜ ì˜ˆì‹œ, ì‘ë‹µì— ê·¼ê±°í•œ ë‚´ìš© ë“±ì„ í¬í•¨í•œ ë‹¤ì–‘í•œ ë¬¸ë§¥ ì†ŒìŠ¤ì™€ ëª¨ë¸ì˜ ì—°ê²°\\n\\nâ†’ ì–¸ì–´ ëª¨ë¸ì€ ì œê³µëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë” ì •í™•í•˜ê³  ê´€ë ¨ì„± ë†’ì€ ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ìˆë‹¤.\\n\\në¬¸ë§¥ ì¸ì‹\\n\\nì–¸ì–´ ëª¨ë¸ì€ ì£¼ì–´ì§„ ë¬¸ë§¥ì„ ë°”íƒ•ìœ¼ë¡œ ì–´ë–¤ ë‹µë³€ì„ ì œê³µí•˜ê±°ë‚˜ ì–´ë–¤ ì¡°ì·¨ë¥¼ ì·¨í•´ì•¼ í• ì§€ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡ í•  ìˆ˜ ìˆë‹¤\\n\\nâ†’ ë‹¨ìˆœíˆ ì •ë³´ ì¬ìƒì‚°ì´ ì•„ë‹ˆë¼ ì£¼ì–´ì§„ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ í•´ê²°ì±… ì œì‹œ ê°€ëŠ¥\\n\\nì¶”ë¡ \\n\\n\\n\\n3\\n\\nLangChain\\n\\nLangSmith\\n\\nLLM ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œ, ëª¨ë‹ˆí„°ë§ ë° í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í”Œë«í¼\\n\\në‹¨ìˆœíˆ ì •ë³´ ì¬ìƒì‚°ì´ ì•„ë‹ˆë¼ ì£¼ì–´ì§„ ìƒí™©ì„ ë¶„ì„í•˜ê³  ì ì ˆí•œ í•´ê²°ì±… ì œì‹œ ê°€ëŠ¥\\n\\nì¶”ì  ê¸°ëŠ¥\\n\\nì˜ˆìƒì¹˜ ëª»í•œ ìµœì¢… ê²°ê³¼, ì²´ì¸ì´ ì˜ˆìƒë³´ë‹¤ ëŠë¦° ì´ìœ  ë“±ì— ëŒ€í•´ ì¶”ì í•˜ëŠ”ë° ë„ì›€ì´ ë  ìˆ˜ ìˆë‹¤\\n\\n\\n\\n3\\n\\nLangChain\\n\\nLangSmith\\n\\nhttps://smith.langchain.com\\n\\n- ë§ˆì°¬ê°€ì§€ë¡œ í‚¤ ë°œê¸‰(â˜…â˜…â˜…â˜…â˜…â˜…ì €ì¥í•„ìˆ˜)\\n\\n- .envì— ë„£ì–´ì•¼ í•  í•­ëª©\\n\\n```\\n\\nLANGCHAIN_TRACING_V2 = true\\n\\nLANGCHAIN_ENDPOINT = https://api.langchain.com\\n\\nLANGCHAIN_API_KEY = ë°œê¸‰ë°›ì€ í‚¤\\n\\nLANGCHAIN_PROJECT = í”„ë¡œì íŠ¸ëª…\\n\\n```\\n\\n\\n\\nê°ì‚¬í•©ë‹ˆë‹¤.\\n\\nThank You')]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "url1 = 'https://www.naver.com/'\n",
    "url2 = 'https://finance.naver.com/'\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_path = (url1, url2),\n",
    "    bs_kwargs = dict(\n",
    "        parse_only = bs4.SoupStrainer(\n",
    "            # class_ = ('article-header','article-content','menu')\n",
    "            # name = ('div')\n",
    "            text='ë©”ì¼'\n",
    "            # string='ì¦ê¶Œ' # í…ìŠ¤íŠ¸ì— \"ë©”ì¼\"ì´ í¬í•¨ëœ ë¶€ë¶„ë§Œ í•„í„°ë§\n",
    "            string=lambda text: text and \"ì¦ê¶Œ\" in text # \"ë©”ì¼\"ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸ë§Œ í•„í„°ë§\n",
    "        )\n",
    "    )\n",
    ")\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://finance.naver.com/'}, page_content=\"ë„¤ì´ë²„í˜ì´ ì¦ê¶Œì¦ê¶Œì¦ê¶Œ ì¢…ëª©ëª…Â·ì§€ìˆ˜ëª… ê²€ìƒ‰ì¦ê¶Œ í™ˆâ€˜ì‹œì´ 2800ì–µâ€™ í˜„ëŒ€ì°¨ì¦ê¶Œ, 2000ì–µì› ìœ ì¦â€¦ì£¼ê°€ í­ë½ì— ë¿”ë‚œ ì£¼ì£¼ë“¤ì˜ë‚˜ê°€ëŠ” ì‚¼ì„± ë³´í—˜ë§¨â€¦ í™”ì¬Â·ì¦ê¶Œ ì´ì–´ 'ìš´ìš©' CEOë„ 'ìƒëª…' ì¶œì‹ ìœ¼ë¡œPC ì¦ê¶Œ í•´ì™¸ ì¢…ëª© ê²€ìƒ‰ ë„ì… ...ì¦ê¶Œ ê³ ê°ì„¼í„°\")"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ì¦ê¶Œ'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://www.naver.com/'}, page_content=' ìƒë‹¨ì˜ì—­ ë°”ë¡œê°€ê¸° ì„œë¹„ìŠ¤ ë©”ë‰´ ë°”ë¡œê°€ê¸° ìƒˆì†Œì‹ ë¸”ë¡ ë°”ë¡œê°€ê¸° ì‡¼í•‘ ë¸”ë¡ ë°”ë¡œê°€ê¸° ê´€ì‹¬ì‚¬ ë¸”ë¡ ë°”ë¡œê°€ê¸° MY ì˜ì—­ ë°”ë¡œê°€ê¸° ìœ„ì ¯ ë³´ë“œ ë°”ë¡œê°€ê¸° ë³´ê¸° ì„¤ì • ë°”ë¡œê°€ê¸°             ê²€ìƒ‰                       ê²€ìƒ‰       ì…ë ¥ë„êµ¬     ìë™ì™„ì„±/ìµœê·¼ê²€ìƒ‰ì–´í¼ì¹˜ê¸°                     ')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://finance.naver.com/'}, page_content='')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arxiv.org : ë…¼ë¬¸ ë¶ˆëŸ¬ì˜¤ëŠ” ì‚¬ì´íŠ¸\n",
    "loader = ArxivLoader(\n",
    "    query = 'ChatGPT', # ë…¼ë¬¸ì˜ ì£¼ì œ\n",
    "    load_max_docs = 2, # ìµœëŒ€ ë¬¸ì„œ ìˆ˜\n",
    "    load_all_available_meta = False # ë©”íƒ€ë°ì´í„° ì „ì²´ë¥¼ ë¡œë“œí• ì§€ì˜ ì—¬ë¶€(false í•´ë„ ì œëª© ì‘ì„±ì ìš”ì•½ì€ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2023-10-05',\n",
       " 'Title': 'In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT',\n",
       " 'Authors': 'Xinyue Shen, Zeyuan Chen, Michael Backes, Yang Zhang',\n",
       " 'Summary': \"The way users acquire information is undergoing a paradigm shift with the\\nadvent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves\\nknowledge from the model itself and generates answers for users. ChatGPT's\\nimpressive question-answering (QA) capability has attracted more than 100\\nmillion users within a short period of time but has also raised concerns\\nregarding its reliability. In this paper, we perform the first large-scale\\nmeasurement of ChatGPT's reliability in the generic QA scenario with a\\ncarefully curated set of 5,695 questions across ten datasets and eight domains.\\nWe find that ChatGPT's reliability varies across different domains, especially\\nunderperforming in law and science questions. We also demonstrate that system\\nroles, originally designed by OpenAI to allow users to steer ChatGPT's\\nbehavior, can impact ChatGPT's reliability in an imperceptible way. We further\\nshow that ChatGPT is vulnerable to adversarial examples, and even a single\\ncharacter change can negatively affect its reliability in certain cases. We\\nbelieve that our study provides valuable insights into ChatGPT's reliability\\nand underscores the need for strengthening the reliability and security of\\nlarge language models (LLMs).\"}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Published': '2023-12-30',\n",
       " 'Title': 'Is ChatGPT Involved in Texts? Measure the Polish Ratio to Detect ChatGPT-Generated Text',\n",
       " 'Authors': 'Lingyi Yang, Feng Jiang, Haizhou Li',\n",
       " 'Summary': 'The remarkable capabilities of large-scale language models, such as ChatGPT,\\nin text generation have impressed readers and spurred researchers to devise\\ndetectors to mitigate potential risks, including misinformation, phishing, and\\nacademic dishonesty. Despite this, most previous studies have been\\npredominantly geared towards creating detectors that differentiate between\\npurely ChatGPT-generated texts and human-authored texts. This approach,\\nhowever, fails to work on discerning texts generated through human-machine\\ncollaboration, such as ChatGPT-polished texts. Addressing this gap, we\\nintroduce a novel dataset termed HPPT (ChatGPT-polished academic abstracts),\\nfacilitating the construction of more robust detectors. It diverges from extant\\ncorpora by comprising pairs of human-written and ChatGPT-polished abstracts\\ninstead of purely ChatGPT-generated texts. Additionally, we propose the \"Polish\\nRatio\" method, an innovative measure of the degree of modification made by\\nChatGPT compared to the original human-written text. It provides a mechanism to\\nmeasure the degree of ChatGPT influence in the resulting text. Our experimental\\nresults show our proposed model has better robustness on the HPPT dataset and\\ntwo existing datasets (HC3 and CDB). Furthermore, the \"Polish Ratio\" we\\nproposed offers a more comprehensive explanation by quantifying the degree of\\nChatGPT involvement.'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The way users acquire information is undergoing a paradigm shift with the\n",
      "advent of ChatGPT. Unlike conventional search engines, ChatGPT retrieves\n",
      "knowledge from the model itself and generates answers for users. ChatGPT's\n",
      "impressive question-answering (QA) capability has attracted more than 100\n",
      "million users within a short period of time but has also raised concerns\n",
      "regarding its reliability. In this paper, we perform the first large-scale\n",
      "measurement of ChatGPT's reliability in the generic QA scenario with a\n",
      "carefully curated set of 5,695 questions across ten datasets and eight domains.\n",
      "We find that ChatGPT's reliability varies across different domains, especially\n",
      "underperforming in law and science questions. We also demonstrate that system\n",
      "roles, originally designed by OpenAI to allow users to steer ChatGPT's\n",
      "behavior, can impact ChatGPT's reliability in an imperceptible way. We further\n",
      "show that ChatGPT is vulnerable to adversarial examples, and even a single\n",
      "character change can negatively affect its reliability in certain cases. We\n",
      "believe that our study provides valuable insights into ChatGPT's reliability\n",
      "and underscores the need for strengthening the reliability and security of\n",
      "large language models (LLMs).\n"
     ]
    }
   ],
   "source": [
    "docs = loader.get_summaries_as_docs()\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
