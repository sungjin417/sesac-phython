# ìƒˆë¡œìš´ íŒŒì¼ ë§Œë“¤ê³  pyí™•ì¥ìë¡œ ì €ì¥í•˜ê¸°
import streamlit as st

# ìŠ¤íŠ¸ë¦¼ë¦¿ ì˜ˆì‹œ

# text = 'í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.'
# st.header(text, divider = 'rainbow') # divider : êµ¬ë¶„ì
# st.title(text)
# st.write(text)
# st.write('### ë¬¸ì¥ì„ ë„£ìŠµë‹ˆë‹¤')
# st.write('# ë¬¸ì¥ì„ ë„£ìŠµë‹ˆë‹¤')
# vocab_logits = {'ë‚˜ëŠ”' : 0.3, 'ë°¥ì„' : 0.2, 'ë¨¹ëŠ”ë‹¤' : 0.5}
# st.bar_chart(vocab_logits) # ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
# prompt = st.chat_input('ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”') # chat_input : inputì°½ ë§Œë“¤ê¸°

import streamlit as st
from langchain.document_loaders import WebBaseLoader
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
import os
from dotenv import load_dotenv
import bs4
from langchain_teddynote import logging

load_dotenv()
# gpt-4o ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(
    model = 'gpt-4o',
    temperature=0.2, # 0ì€ ë„ˆë¬´ ë”±ë”±í•¨ .2
    openai_api_key = os.getenv('OPENAI_API_KEY')
)

# íƒ€ì´í‹€
st.title('ë‰´ìŠ¤ ê¸°ë°˜ ëŒ€í™”í˜• ì±—ë´‡ ğŸ‘¾ğŸ¤–')
st.markdown('ë‰´ìŠ¤ URLì„ ì…ë ¥í•˜ë©´ í•´ë‹¹ ë‰´ìŠ¤ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤')

# ìƒíƒœê´€ë¦¬ (ìƒíƒœê´€ë¦¬ì—ì„œ ì´ˆê¸°í™” í• ë•ŒëŠ” ë¬¸ìì—´ í˜•íƒœë¡œ ë„£ì–´ì£¼ëŠ”ê²Œ ì¼ë°˜ì )
if 'vector_store' not in st.session_state:
    st.session_state.vector_store = None
if 'memory' not in st.session_state:
    st.session_state.memory = ConversationBufferMemory(memory_key = 'chat_history', return_messages = True)
if 'messages_displayed' not in st.session_state:
    st.session_state.messages_displayed = []


# ë‰´ìŠ¤ ë¡œë“œ
news_url = st.text_input('ë‰´ìŠ¤ URL ì…ë ¥ : ')
if st.button('ë‰´ìŠ¤ ë¡œë“œ'):
    if not news_url:
        st.error('URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.')
    else:
        try:
            loader = WebBaseLoader(
                web_paths = (news_url,), # (news_url,) : íŠœí”Œë¡œ ê°„ì£¼í•˜ê¸° ìœ„í•´ì„œ , ì¶”ê°€
                bs_kwargs = dict(
                    parse_only = bs4.SoupStrainer(
                        'div',
                        attrs = {
                            'class' : ['newsct_article _article_body', 'media_end_head_title']
                        }
                    )

                )
            )
            docs = loader.load()

            if not docs:
                st.error('ë‰´ìŠ¤ ë‚´ìš©ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”,')
            else:
                st.success(f'ë¬¸ì„œë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë¬¸ì„œ ê°œìˆ˜ : {len(docs)}')

                # ë¬¸ì„œ ë¶„í• 
                splitter = CharacterTextSplitter(chunk_size = 500, chunk_overlap = 50)
                split_texts = splitter.split_documents(docs)

                #ì„ë² ë”©
                embeddings = OpenAIEmbeddings()
                vector_store = FAISS.from_documents(split_texts, embeddings)

                st.session_state.vector_store = vector_store

        
        except Exception as e:
            st.error(f'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ : {str(e)}')
            
prompt = st.chat_input('ë©”ì„¸ì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.')
if prompt:
    if st.session_state.vector_store is None:
        st.error('ë‰´ìŠ¤ë¥¼ ë¨¼ì € ë¡œë“œí•´ ì£¼ì„¸ìš”')
    else:
        # ì‚¬ìš©ì ë©”ì„¸ì§€ ê¸°ë¡
        st.session_state.memory.chat_memory.add_user_message(prompt)
        try:
            retriever = st.session_state.vector_store.as_retriever()
            chain = ConversationalRetrievalChain.from_llm(
               llm = llm,
               retriever =retriever,
               memory = st.session_state.memory 
            )
            # AI ì‘ë‹µ ìƒì„±
            response = chain({'question' : prompt})
            ai_response = response['answer']

            #AI ë©”ì‹œì§€ ê¸°ë¡
            st.session_state.memory.chat_memory.add_ai_message(ai_response)

            # ë©”ì„¸ì§€ í‘œì‹œ
            st.session_state.messages_displayed.append({'role' : 'user', 'content' : prompt})
            st.session_state.messages_displayed.append({'role' : 'assistant' , 'content' : ai_response})
        except Exception as e:
            st.error(f'ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ : {str(e)}')

for message in st.session_state.messages_displayed:
    with st.chat_message(message['role']):
        st.write(message['content'])
