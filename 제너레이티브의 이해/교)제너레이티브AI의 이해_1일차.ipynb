{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸŒ¼ ì œë„ˆë ˆì´í‹°ë¸ŒAIì˜ ì´í•´ - 1ì°¨ì‹œ(24.11.18)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VAE(Variational Auto Encoder)\n",
    "- ëª¨ë¸ì´ ìˆ«ì ì´ë¯¸ì§€ë¥¼ ì••ì¶•í•˜ê³ , ë³µì›í•˜ëŠ” ê³¼ì •(ì¸ì½”ë”-ë””ì½”ë”)\n",
    "- ì¸ì½”ë” : ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì ì¬ê³µê°„ìœ¼ë¡œ ë§¤í•‘\n",
    "- ë””ì½”ë” : ì ì¬ ê³µê°„ì—ì„œ ìƒ˜í”Œì„ ë°›ì•„ ì´ë¯¸ì§€ ë³µì›\n",
    "- ê°€ìƒí™˜ê²½ ì‹¤í–‰ í›„ - pip install opencv-pythonë¡œ ì„¤ì¹˜!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflowë¥¼ í™œìš©í•œ celebë°ì´í„°ì…‹ì— VAE ì ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\RMARKET\\.cache\\kagglehub\\datasets\\yunting0123\\img-align-celeba\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yunting0123/img-align-celeba\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "image_dir = \"C:/Users/RMARKET/.cache/kagglehub/datasets/yunting0123/img-align-celeba/versions/1/t/celebA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'030000.png'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_filenames = os.listdir(image_dir)[-1]\n",
    "img_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬ í•˜ëŠ” í•¨ìˆ˜ ë§Œë“¤ê¸°\n",
    "def load_preprocess_images(image_dir, img_size = (128, 128), num_images = 10000):\n",
    "    # ê²½ë¡œ, ì´ë¯¸ì§€ í¬ê¸°, ìµœëŒ€ ë¡œë“œí•  ì´ë¯¸ì§€ ê°œìˆ˜\n",
    "    images = []\n",
    "    # ì „ì²˜ë¦¬ ëœ ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•  ë¦¬ìŠ¤íŠ¸\n",
    "    img_filenames = os.listdir(image_dir)[:num_images]\n",
    "    for filename in img_filenames:\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ image_dir(íŒŒì¼ ê²½ë¡œ) + filename(íŒŒì¼ ì´ë¦„)ìœ¼ë¡œ ë§Œë“¤ì–´ ì£¼ê¸°\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img / 255.0 # ì´ë¯¸ì§€ ì •ê·œí™”\n",
    "            # ì •ê·œí™” ê³¼ì •\n",
    "            # rgb [204, 76, 128] -> [0.8, 0.3, 0.5]\n",
    "            images.append(img)\n",
    "    return np.array(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.78823529, 0.88627451, 0.94901961],\n",
       "         [0.84705882, 0.92156863, 0.96862745],\n",
       "         [0.87843137, 0.9372549 , 0.98039216]],\n",
       "\n",
       "        [[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.79607843, 0.89411765, 0.95294118],\n",
       "         [0.85098039, 0.92156863, 0.97254902],\n",
       "         [0.87843137, 0.9372549 , 0.98039216]],\n",
       "\n",
       "        [[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.81960784, 0.90588235, 0.96078431],\n",
       "         [0.85490196, 0.9254902 , 0.97647059],\n",
       "         [0.8745098 , 0.93333333, 0.98431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.23529412, 0.40392157, 0.6745098 ],\n",
       "         [0.22745098, 0.39215686, 0.6627451 ],\n",
       "         [0.21176471, 0.37254902, 0.63921569],\n",
       "         ...,\n",
       "         [0.0627451 , 0.16078431, 0.40784314],\n",
       "         [0.0627451 , 0.16078431, 0.40392157],\n",
       "         [0.0627451 , 0.16078431, 0.40392157]],\n",
       "\n",
       "        [[0.2       , 0.36078431, 0.63921569],\n",
       "         [0.20784314, 0.37254902, 0.64705882],\n",
       "         [0.22745098, 0.39215686, 0.67058824],\n",
       "         ...,\n",
       "         [0.07843137, 0.18039216, 0.43921569],\n",
       "         [0.0745098 , 0.18039216, 0.43529412],\n",
       "         [0.0745098 , 0.18039216, 0.43529412]],\n",
       "\n",
       "        [[0.18039216, 0.34117647, 0.61960784],\n",
       "         [0.19607843, 0.36078431, 0.63921569],\n",
       "         [0.23137255, 0.4       , 0.68235294],\n",
       "         ...,\n",
       "         [0.08627451, 0.18823529, 0.45490196],\n",
       "         [0.08235294, 0.18823529, 0.45098039],\n",
       "         [0.08235294, 0.18823529, 0.45098039]]],\n",
       "\n",
       "\n",
       "       [[[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28235294, 0.29803922],\n",
       "         [0.28235294, 0.30196078, 0.31764706],\n",
       "         [0.29019608, 0.31372549, 0.3254902 ]],\n",
       "\n",
       "        [[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28235294, 0.29803922],\n",
       "         [0.28235294, 0.30588235, 0.31764706],\n",
       "         [0.29019608, 0.31372549, 0.3254902 ]],\n",
       "\n",
       "        [[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28627451, 0.29803922],\n",
       "         [0.28627451, 0.30588235, 0.31764706],\n",
       "         [0.29411765, 0.31764706, 0.32941176]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.80784314, 0.78431373, 0.77647059],\n",
       "         [0.81176471, 0.79215686, 0.78431373],\n",
       "         [0.82745098, 0.80392157, 0.8       ],\n",
       "         ...,\n",
       "         [0.4       , 0.41960784, 0.53333333],\n",
       "         [0.45882353, 0.47058824, 0.55686275],\n",
       "         [0.48627451, 0.49803922, 0.57254902]],\n",
       "\n",
       "        [[0.85882353, 0.83529412, 0.83529412],\n",
       "         [0.85490196, 0.83529412, 0.83529412],\n",
       "         [0.85098039, 0.83137255, 0.83137255],\n",
       "         ...,\n",
       "         [0.38039216, 0.40784314, 0.52941176],\n",
       "         [0.43137255, 0.45098039, 0.54901961],\n",
       "         [0.45882353, 0.47058824, 0.56078431]],\n",
       "\n",
       "        [[0.88235294, 0.8627451 , 0.86666667],\n",
       "         [0.8745098 , 0.85490196, 0.85882353],\n",
       "         [0.8627451 , 0.84313725, 0.84705882],\n",
       "         ...,\n",
       "         [0.37254902, 0.4       , 0.5254902 ],\n",
       "         [0.41960784, 0.43921569, 0.54509804],\n",
       "         [0.44313725, 0.45882353, 0.55294118]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.22352941, 0.34117647, 0.51764706],\n",
       "         [0.21960784, 0.34509804, 0.5254902 ],\n",
       "         [0.21568627, 0.36078431, 0.54117647],\n",
       "         ...,\n",
       "         [0.25098039, 0.23921569, 0.23921569],\n",
       "         [0.25490196, 0.24313725, 0.24705882],\n",
       "         [0.25882353, 0.24705882, 0.25098039]],\n",
       "\n",
       "        [[0.22745098, 0.32156863, 0.48235294],\n",
       "         [0.22352941, 0.3254902 , 0.49019608],\n",
       "         [0.21568627, 0.34509804, 0.51372549],\n",
       "         ...,\n",
       "         [0.24313725, 0.23529412, 0.23921569],\n",
       "         [0.24705882, 0.23921569, 0.24313725],\n",
       "         [0.25098039, 0.24313725, 0.24705882]],\n",
       "\n",
       "        [[0.22745098, 0.30980392, 0.4627451 ],\n",
       "         [0.22352941, 0.31764706, 0.4745098 ],\n",
       "         [0.21960784, 0.3372549 , 0.49803922],\n",
       "         ...,\n",
       "         [0.23921569, 0.23137255, 0.23529412],\n",
       "         [0.24313725, 0.23529412, 0.23921569],\n",
       "         [0.24705882, 0.23921569, 0.24313725]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.71372549, 0.69411765, 0.69803922],\n",
       "         [0.71764706, 0.69803922, 0.70196078],\n",
       "         [0.72941176, 0.70980392, 0.71372549],\n",
       "         ...,\n",
       "         [0.75294118, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.72941176],\n",
       "         [0.74901961, 0.72941176, 0.72941176]],\n",
       "\n",
       "        [[0.70588235, 0.68627451, 0.69019608],\n",
       "         [0.70980392, 0.69019608, 0.69411765],\n",
       "         [0.72156863, 0.70196078, 0.70588235],\n",
       "         ...,\n",
       "         [0.75294118, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.72941176]],\n",
       "\n",
       "        [[0.68627451, 0.66666667, 0.67058824],\n",
       "         [0.69019608, 0.67058824, 0.6745098 ],\n",
       "         [0.70588235, 0.68627451, 0.69019608],\n",
       "         ...,\n",
       "         [0.74901961, 0.72941176, 0.73333333],\n",
       "         [0.74901961, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.73333333, 0.73333333]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.78823529, 0.76862745, 0.76470588],\n",
       "         [0.78823529, 0.76862745, 0.76470588],\n",
       "         [0.78823529, 0.76862745, 0.76470588],\n",
       "         ...,\n",
       "         [0.87058824, 0.8627451 , 0.87843137],\n",
       "         [0.8745098 , 0.86666667, 0.87843137],\n",
       "         [0.87843137, 0.86666667, 0.87843137]],\n",
       "\n",
       "        [[0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         ...,\n",
       "         [0.87058824, 0.86666667, 0.88235294],\n",
       "         [0.87843137, 0.86666667, 0.87843137],\n",
       "         [0.88235294, 0.87058824, 0.87843137]],\n",
       "\n",
       "        [[0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         ...,\n",
       "         [0.8745098 , 0.86666667, 0.88235294],\n",
       "         [0.87843137, 0.87058824, 0.87843137],\n",
       "         [0.88235294, 0.87058824, 0.87843137]]],\n",
       "\n",
       "\n",
       "       [[[0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        [[0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        [[0.5254902 , 0.49411765, 0.42745098],\n",
       "         [0.5254902 , 0.49411765, 0.42745098],\n",
       "         [0.5254902 , 0.49411765, 0.42745098],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.92156863, 0.94509804, 0.94509804],\n",
       "         [0.91764706, 0.9372549 , 0.94117647],\n",
       "         [0.90196078, 0.9254902 , 0.92941176],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54117647, 0.49803922, 0.44313725]],\n",
       "\n",
       "        [[0.93333333, 0.94901961, 0.94901961],\n",
       "         [0.9254902 , 0.94117647, 0.94509804],\n",
       "         [0.91372549, 0.92941176, 0.93333333],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882]],\n",
       "\n",
       "        [[0.9372549 , 0.95294118, 0.95294118],\n",
       "         [0.92941176, 0.94509804, 0.94509804],\n",
       "         [0.91764706, 0.93333333, 0.93333333],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882]]],\n",
       "\n",
       "\n",
       "       [[[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        [[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        [[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.83529412, 0.83921569, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.81568627, 0.81960784, 0.81960784],\n",
       "         ...,\n",
       "         [0.2       , 0.26666667, 0.38039216],\n",
       "         [0.19607843, 0.26666667, 0.38039216],\n",
       "         [0.19215686, 0.26666667, 0.38431373]],\n",
       "\n",
       "        [[0.83137255, 0.83529412, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.82352941, 0.82352941, 0.82352941],\n",
       "         ...,\n",
       "         [0.17647059, 0.23529412, 0.35294118],\n",
       "         [0.17647059, 0.23921569, 0.36078431],\n",
       "         [0.18039216, 0.24313725, 0.36470588]],\n",
       "\n",
       "        [[0.83137255, 0.83529412, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.82352941, 0.82745098, 0.82352941],\n",
       "         ...,\n",
       "         [0.16470588, 0.21960784, 0.3372549 ],\n",
       "         [0.16862745, 0.22745098, 0.34901961],\n",
       "         [0.17254902, 0.23137255, 0.35294118]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = load_preprocess_images(image_dir)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ìƒ˜í”Œë§ í•¨ìˆ˜ ì •ì˜\n",
    "# ì ì¬ê³µê°„ì—ì„œ ìƒˆë¡œìš´ ìƒ˜í”Œì„ ìƒì„±í•˜ê¸° ìœ„í•´ ë°ì´í„°í¬ì´íŠ¸ë“¤ì„ ìƒ˜í”Œë§í•˜ëŠ” ê³¼ì •\n",
    "# ê° ë°ì´í„°í¬ì¸í„°ë“¤ì˜ í‰ê· ê°’ê³¼ ë¡œê·¸ ë¶„ì‚°ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def sampling(z_mean, z_log_var):\n",
    "    # ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°í¬ì¸íŠ¸(z)ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŒ\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    # ë”¥ëŸ¬ë‹í”„ë ˆì„ì›Œí¬ëŠ” ë°ì´í„° ì…ë ¥ì‹œ ìë™ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸°ë¥¼ ê°ì§€\n",
    "    # 0ë²ˆì§¸ ìë¦¬ì˜ ê°’ì´ batch ì‚¬ì´ì¦ˆì´ë¯€ë¡œ batchë¼ëŠ” ì´ë¦„ì˜ ë³€ìˆ˜ë¡œ ì €ì¥í•œ ê²ƒ\n",
    "\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    # ì ì¬ê³µê°„ì˜ ì°¨ì›ê°’\n",
    "\n",
    "    epsilon = tf.random.normal(shape = (batch, dim))\n",
    "    # ë°°ì¹˜ì‚¬ì´ì¦ˆì™€ ì°¨ì›ì˜ shapeì„ ê°–ëŠ” í‘œì¤€ì •ê·œë¶„í¬ì˜ ë¬´ì‘ìœ„ê°’ ìƒì„±\n",
    "\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "# tf.exp(0.5 z_log_var) -> ë¡œê·¸ ë¶„ì‚°ì„ í‘œì¤€í¸ì°¨ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •, ë¡œê·¸ë¶„ì‚°ì— 0.5ë¥¼ ê³±í•˜ê³  ì§€ìˆ˜í•¨ìˆ˜ë¥¼ ì ìš© -> í‘œì¤€í¸ì°¨ë¥¼ êµ¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ì¸ì½”ë” ì •ì˜\n",
    "latent_dim = 200\n",
    "# ì ì¬ê³µê°„ì˜ ì°¨ì›\n",
    "# ê°„ë‹¨í•œ ë°ì´í„°ë‚˜ í…ŒìŠ¤íŠ¸ëª©ì  : 2 ~ 10 ì •ë„\n",
    "# ë³µì¡í•œ ì´ë¯¸ì§€ë‚˜ ê³ ì°¨ì› : 100 ~ 200 ì‚¬ìš©\n",
    "\n",
    "encoder_input = keras.layers.Input(shape = (128, 128, 3), name='encoder_input') # shape = (ê°€ë¡œ, ì„¸ë¡œ, ì°¨ì›(ì»¬ëŸ¬(rgb)))\n",
    "# 128x128 ì‚¬ì´ì¦ˆì˜ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì¸í’‹ìœ¼ë¡œ ë„£ì„ ê²ƒì„ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•œ ê²ƒ\n",
    "x = keras.layers.Conv2D(32, (3,3), strides = 2, activation = 'relu', padding = 'same')(encoder_input) # padding = 'same' : ê°€ì¥ìë¦¬ì— íŒ¨ë”©ì´ ë“¤ì–´ê°€ê¸° ìœ„í•´(ì…ë ¥ê³¼ ì¶œë ¥ê°’ì´ ê°™ê²Œ í•˜ê¸° ìœ„í•´)\n",
    "# Conv2D : ê³µê°„ì ì¸ íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥\n",
    "# 32ê°œ í•„í„°, (3,3)ì»¤ë„, ìŠ¬ë¼ì´ë”© ê°„ê²© 2\n",
    "x = keras.layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2D(128,  (3,3), strides = 2, activation= 'relu', padding='same')(x)\n",
    "# í…ì„œ : ë”¥ëŸ¬ë‹ ì ì¸ ì—°ì‚°ì´ ê°€ëŠ¥í•˜ë‹¤\n",
    "# x.sahpe = (batch_size, height, width, channels)\n",
    "shape_before_flattening = x.shape[1:]\n",
    "# xë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸° ì „ ì •ë³´ ì €ì¥\n",
    "\n",
    "# 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ : Conv2DëŠ” ì´ë¯¸ì§€ì˜ ê³µê°„ì ì¸ êµ¬ì¡°ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë‚˜ ê²°ì •ì„ ë‚´ë¦´ ìˆœ ì—†ìŒ\n",
    "# ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆëŠ” Denseì¸µì„ ìŒ“ì•„ì£¼ê¸° ìœ„í•´ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜(flatten, í‰íƒ„í™”)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "# ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„\n",
    "z_mean = keras.layers.Dense(latent_dim, name = 'z_mean')(x)\n",
    "z_log_var = keras.layers.Dense(latent_dim, name = 'z_log_var')(x)\n",
    "# ë‘ ë ˆì´ì–´ëŠ” ë™ì¼í•œ ì…ë ¥ xë¥¼ ë°›ì§€ë§Œ, ì†ì‹¤í•¨ìˆ˜ì™€ ì—­ì „íŒŒ ê³¼ì •ì— ì˜í•´ ë‹¤ë¥¸ ì¶œë ¥ì„ í•™ìŠµ\n",
    "\n",
    "z = sampling(z_mean, z_log_var)\n",
    "# ë¬´ì‘ìœ„ ë²¡í„°ê°’ ìƒì„±\n",
    "\n",
    "encoder = keras.models.Model(encoder_input, [z_mean, z_log_var, z], name = 'encoder')\n",
    "# ëª¨ë¸ì€ 3ê°œì˜ ì¶œë ¥ì„ ë°˜í™˜í•œë‹¤\n",
    "# z_mean : ì¸ì½”ë”ê°€ í•™ìŠµí•œ ì ì¬ ê³µê°„ì˜ í‰ê·  ë²¡í„°\n",
    "# z_log_var : ì¸ì½”ë”ê°€ í•™ìŠµí•œ ë¡œê·¸ ë¶„ì‚° ë²¡í„°\n",
    "# z : í‰ê· ê³¼ ë¶„ì‚°ì„ ì‚¬ìš©í•´ ìƒ˜í”Œë§ëœ ì ì¬ ê³µê°„ì˜ ë²¡í„°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ë””ì½”ë” ì •ì˜\n",
    "decoder_input = keras.layers.Input(shape = (latent_dim,), name='decoder_input')\n",
    "x = keras.layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "# Dense ë ˆì´ì–´ë¡œ ì ì¬ê³µê°„ì˜ ë²¡í„°ë¥¼ ë””ì½”ë” ì¶œë ¥ì— ë§ê²Œ ë³€í™˜\n",
    "# prod : ì´ í˜•íƒœì˜ ëª¨ë“  ì°¨ì›ì„ ê³±í•´ 1ì°¨ì› ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "# (16,16,128) -> 16x16x128\n",
    "# ë¨¼ì € ìœ„ì—ì„œ ì €ì¥í–ˆë˜ flattenì „ ë§ˆì§€ë§‰ 3ì°¨ì›ì„ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜ í›„ Denseë ˆì´ì–´ì— ì ìš©\n",
    "\n",
    "x = keras.layers.Reshape(shape_before_flattening)(x)\n",
    "# ì›ë˜ ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ ì¶œë ¥ í˜•íƒœì¸ 3ì°¨ì› í…ì„œë¡œ ë‹¤ì‹œ reshape\n",
    "x = keras.layers.Conv2DTranspose(128, (3,3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2DTranspose(64, (3,3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2DTranspose(32, (3,3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "\n",
    "decoder_output = keras.layers.Conv2D(3, (3,3), strides = 1, activation = 'sigmoid', padding='same', name='decoder_output')(x)\n",
    "decoder = keras.models.Model(decoder_input, decoder_output, name = 'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. í•™ìŠµ ë£¨í”„ ë§Œë“¤ê¸°\n",
    "def train_step(data):\n",
    "    with tf. GradientTape() as tape:\n",
    "        # with tf. GradientTape() : tensorflowì—ì„œ ìë™ ë¯¸ë¶„ì„ ìœ„í•´ ì„¤ì €í•˜ëŠ” withë¬¸\n",
    "        z_mean, z_log_var, z = encoder(data)\n",
    "        recon = decoder(z)\n",
    "        # recon : ì¬êµ¬ì„±ëœ ì´ë¯¸ì§€ / ì…ë ¥ë°ì´í„°ì™€ ë¹„êµë  ì´ë¯¸ì§€\n",
    "        recon_loss = tf.reduce_mean(500 * tf.losses.binary_crossentropy(data,recon))\n",
    "        # ì›ë³¸ ë°ì´í„°ì™€ ì¬êµ¬ì„±ëœ ì´ë¯¸ì§€ ë°ì´í„° ê°„ì˜ ì°¨ì´ë¥¼\n",
    "        # í”½ì…€ì˜ ì´ì§„ë¶„í¬ë¡¤ ê³„ì‚°\n",
    "        # ê°€ì¤‘ì¹˜ë¥¼ 500 ê³±í•´ì„œ ì¡°ì •\n",
    "        # reduce_mean : ë°°ì¹˜ ë‚´ ëª¨ë“  ë°ì´í„°í¬ì¸íŠ¸ì˜ í‰ê· ì†ì‹¤ì„ ê³„ì‚°í•œë‹¤ëŠ” ì˜ë¯¸\n",
    "\n",
    "        # 2. KL-ë°œì‚° ì†ì‹¤\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean)-tf.exp(z_log_var)), axis = 1)) \n",
    "        # KL ë°œì‚°ì˜ ê³µì‹ : (1 + z_log_var - tf.square(z_mean)-tf.exp(z_log_var))\n",
    "        # axis = 1ì˜µì…˜ì„ ë„£ì—ˆê¸° ë•Œë¬¸ì— ê° ì°¨ì›ì— ëŒ€í•œ í•©ì‚°ì´ ì´ë£¨ì–´ ì§\n",
    "        total_loss = recon_loss + kl_loss\n",
    "    grad = tape.gradient(total_loss, encoder.trainable_weights + decoder.trainable_weights) # trainable_weights : ê°€ì¤‘ì¹˜\n",
    "    optimizer.apply_gradient(zip(grad, encoder.trainable_weights + decoder.trainable_weights)) # ê°ê°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸\n",
    "    # ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ Adamìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "    # ì´ ì†ì‹¤, ì¬êµ¬ì„± ì†ì‹¤, KL-ë°œì‚° ì†ì‹¤ì„ ë°˜í™˜\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(1000).batch(batch_size)\n",
    "# tf.data.Dataset.from_tensor_slices : ì£¼ì–´ì§„ í…ì„œë¥¼ ë°›ì•„ ì´ë¥¼ ê°œë³„ ìŠ¬ë¼ì´ìŠ¤ë¡œ ë‚˜ëˆ  ë°ì´í„°ì…‹ì„ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Adam' object has no attribute 'apply_gradient'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch_data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataset):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# í˜„ì¬ ìŠ¤í…ê³¼ ë°°ì¹˜ë°ì´í„°ë¥¼ ë°˜í™˜\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     total_loss, recon_loss, kl_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# ìŠ¤í…ì´ 100ì˜ ë°°ìˆ˜ì¼ ë•Œ ë§ˆë‹¤\u001b[39;00m\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m : total loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecon loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecon_loss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mKL loss : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkl_loss\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[51], line 20\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     18\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m recon_loss \u001b[38;5;241m+\u001b[39m kl_loss\n\u001b[0;32m     19\u001b[0m grad \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(total_loss, encoder\u001b[38;5;241m.\u001b[39mtrainable_weights \u001b[38;5;241m+\u001b[39m decoder\u001b[38;5;241m.\u001b[39mtrainable_weights) \u001b[38;5;66;03m# trainable_weights : ê°€ì¤‘ì¹˜\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradient\u001b[49m(\u001b[38;5;28mzip\u001b[39m(grad, encoder\u001b[38;5;241m.\u001b[39mtrainable_weights \u001b[38;5;241m+\u001b[39m decoder\u001b[38;5;241m.\u001b[39mtrainable_weights)) \u001b[38;5;66;03m# ê°ê°ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ Adamìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss, recon_loss, kl_loss\n",
      "File \u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:876\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hyper:\n\u001b[0;32m    875\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_hyper(name)\n\u001b[1;32m--> 876\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py:866\u001b[0m, in \u001b[0;36mOptimizerV2.__getattribute__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Overridden to support hyperparameter access.\"\"\"\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 866\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mOptimizerV2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    868\u001b[0m   \u001b[38;5;66;03m# Needed to avoid infinite recursion with __setattr__.\u001b[39;00m\n\u001b[0;32m    869\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_hyper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Adam' object has no attribute 'apply_gradient'"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1} / {epochs}')\n",
    "    for step, batch_data in enumerate(dataset):\n",
    "        # í˜„ì¬ ìŠ¤í…ê³¼ ë°°ì¹˜ë°ì´í„°ë¥¼ ë°˜í™˜\n",
    "        total_loss, recon_loss, kl_loss = train_step(batch_data)\n",
    "        if step % 100 == 0:\n",
    "            # ìŠ¤í…ì´ 100ì˜ ë°°ìˆ˜ì¼ ë•Œ ë§ˆë‹¤\n",
    "            print(f'step{step} : total loss = {total_loss.numpy():.4f},'\n",
    "                  f'recon loss : {recon_loss.numpy():.4f}'\n",
    "                  f'KL loss : {kl_loss.numpy():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Torchë¥¼ í™œìš©í•œ MNISTë°ì´í„°ì…‹ì— VAE ì ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸŒ¼ë§ˆë¬´ë¦¬ ë¬¸ì œ\n",
    "\n",
    "ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì„ ì ìš©í•´ë³´ì„¸ìš”\n",
    "\n",
    "Q1. Fashion MNIST\n",
    "- 28X28 í¬ê¸°ì˜ íŒ¨ì…˜ ì•„ì´í…œ ì´ë¯¸ì§€ë¡œ êµ¬ì„±ëœ í‘ë°± ì´ë¯¸ì§€ ë°ì´í„°ì…‹\n",
    "\n",
    "\n",
    "Q2. CIFAR-10\n",
    "- 32X32 í¬ê¸°ì˜ ìƒ‰ìƒì´ ìˆëŠ” ìë™ì°¨, ë™ë¬¼ ë“± ë‹¤ì–‘í•œ ê°ì²´ê°€ í¬í•¨ëœ ë°ì´í„°ì…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fashion MNIST ë°ì´í„°ì…‹ ë¡œë“œ (28x28 í¬ê¸°ì˜ íŒ¨ì…˜ ì•„ì´í…œ ì´ë¯¸ì§€)\n",
    "trans = transforms.ToTensor()\n",
    "fashion_mnist_data = datasets.FashionMNIST(root='./data', train=True, transform=trans, download=True)\n",
    "data_loader = DataLoader(fashion_mnist_data, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ (32x32 í¬ê¸°ì˜ ì»¬ëŸ¬ ì´ë¯¸ì§€)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # ë°ì´í„° ì •ê·œí™”\n",
    "])\n",
    "cifar10_data = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "data_loader = DataLoader(cifar10_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
