{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸŒ¼ ëŒ€ê·œëª¨ LLMì„ í™œìš©í•œ ì§€ì‹ ì±—ë´‡ ê°œë°œ - 1ì°¨ì‹œ(24.11.21)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import urllib3\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "      <th>lic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src         tar                                                lic\n",
       "0  Go.        Va !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "1  Go.     Marche.  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "2  Go.  En route !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "3  Go.     Bouge !  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
       "4  Hi.     Salut !  CC-BY 2.0 (France) Attribution: tatoeba.org #5..."
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.read_csv('fra.txt', names=['src', 'tar', 'lic'], sep = '\\t')\n",
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "del lines['lic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì „ì²´ ë°ì´í„° ê°œìˆ˜ : 232736\n"
     ]
    }
   ],
   "source": [
    "print(f'ì „ì²´ ë°ì´í„° ê°œìˆ˜ : {len(lines)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Va !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Marche.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Go.</td>\n",
       "      <td>En route !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Go.</td>\n",
       "      <td>Bouge !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>Salut !</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src         tar\n",
       "0  Go.        Va !\n",
       "1  Go.     Marche.\n",
       "2  Go.  En route !\n",
       "3  Go.     Bouge !\n",
       "4  Hi.     Salut !"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24728</th>\n",
       "      <td>You better hurry.</td>\n",
       "      <td>Vous feriez mieux de vous dÃ©pÃªcher !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43219</th>\n",
       "      <td>Our team won 3 to 1.</td>\n",
       "      <td>Notre Ã©quipe a gagnÃ© trois Ã  un.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953</th>\n",
       "      <td>We're engaged.</td>\n",
       "      <td>Nous sommes fiancÃ©s.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34724</th>\n",
       "      <td>I'm feeling guilty.</td>\n",
       "      <td>Je me sens coupable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12703</th>\n",
       "      <td>She is out now.</td>\n",
       "      <td>Elle est en dÃ©placement en ce moment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>Wait a while.</td>\n",
       "      <td>Attendez un moment.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17921</th>\n",
       "      <td>Tom is fearless.</td>\n",
       "      <td>Tom est intrÃ©pide.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29848</th>\n",
       "      <td>This is very good.</td>\n",
       "      <td>TrÃ¨s bien.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26051</th>\n",
       "      <td>Have you gone mad?</td>\n",
       "      <td>ÃŠtes-vous devenue folleâ€¯?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28381</th>\n",
       "      <td>It's kind of hard.</td>\n",
       "      <td>C'est plutÃ´t difficile.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        src                                    tar\n",
       "24728     You better hurry.   Vous feriez mieux de vous dÃ©pÃªcher !\n",
       "43219  Our team won 3 to 1.       Notre Ã©quipe a gagnÃ© trois Ã  un.\n",
       "9953         We're engaged.                   Nous sommes fiancÃ©s.\n",
       "34724   I'm feeling guilty.                   Je me sens coupable.\n",
       "12703       She is out now.  Elle est en dÃ©placement en ce moment.\n",
       "6695          Wait a while.                    Attendez un moment.\n",
       "17921      Tom is fearless.                     Tom est intrÃ©pide.\n",
       "29848    This is very good.                             TrÃ¨s bien.\n",
       "26051    Have you gone mad?              ÃŠtes-vous devenue folleâ€¯?\n",
       "28381    It's kind of hard.                C'est plutÃ´t difficile."
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[:60000]\n",
    "# ë°ì´í„° ê°œìˆ˜ ì¤„ì´ê¸°\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.tar = lines.tar.apply(lambda x : '\\t ' + x + ' \\n')\n",
    "# ì‹œì‘ì„ ì˜ë¯¸í•˜ëŠ” sos, ëì„ ì˜ë¯¸í•˜ëŠ” eos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>No way!</td>\n",
       "      <td>\\t Impossibleâ€¯! \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15606</th>\n",
       "      <td>I like the idea.</td>\n",
       "      <td>\\t L'idÃ©e me plaÃ®t. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44634</th>\n",
       "      <td>Tom is having lunch.</td>\n",
       "      <td>\\t Tom dÃ©jeune. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58437</th>\n",
       "      <td>I'll request a refund.</td>\n",
       "      <td>\\t Je vais demander Ã  Ãªtre remboursÃ©. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22052</th>\n",
       "      <td>It's a snowstorm.</td>\n",
       "      <td>\\t C'est une tempÃªte de neige. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57438</th>\n",
       "      <td>I hope no one sees us.</td>\n",
       "      <td>\\t J'espÃ¨re que personne ne nous voit. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12300</th>\n",
       "      <td>It's not there.</td>\n",
       "      <td>\\t Il n'y est pas. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12566</th>\n",
       "      <td>Now I know why.</td>\n",
       "      <td>\\t Maintenant, je sais pourquoi. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57436</th>\n",
       "      <td>I hope it'll be quiet.</td>\n",
       "      <td>\\t J'espÃ¨re que ce sera calme. \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51776</th>\n",
       "      <td>Thanks for being you.</td>\n",
       "      <td>\\t Merci d'Ãªtre toi. \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          src                                        tar\n",
       "133                   No way!                         \\t Impossibleâ€¯! \\n\n",
       "15606        I like the idea.                     \\t L'idÃ©e me plaÃ®t. \\n\n",
       "44634    Tom is having lunch.                         \\t Tom dÃ©jeune. \\n\n",
       "58437  I'll request a refund.   \\t Je vais demander Ã  Ãªtre remboursÃ©. \\n\n",
       "22052       It's a snowstorm.          \\t C'est une tempÃªte de neige. \\n\n",
       "57438  I hope no one sees us.  \\t J'espÃ¨re que personne ne nous voit. \\n\n",
       "12300         It's not there.                      \\t Il n'y est pas. \\n\n",
       "12566         Now I know why.        \\t Maintenant, je sais pourquoi. \\n\n",
       "57436  I hope it'll be quiet.          \\t J'espÃ¨re que ce sera calme. \\n\n",
       "51776   Thanks for being you.                    \\t Merci d'Ãªtre toi. \\n"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = set()\n",
    "for line in lines['src']:\n",
    "    for char in line:\n",
    "        src_vocab.add(char)\n",
    "        # src ë¬¸ì ì§‘í•© êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p', '\"', 'L', 'X', 'd', ',', 'Q', '0', '9', 'e', '$', 'Ã¯', 'Z', 'v', 'V', 't', '?', 'y', 'o', 'F', 'i', '3', '7', 'Y', 'w', 'G', 'P', '5', 'r', ':', '.', 'k', 'D', 'u', ' ', 'J', 'l', 'n', 'H', 'I', 'K', '%', 'A', 'b', 'â‚¬', 'B', '1', '2', 'â€™', 'M', 'm', 'c', \"'\", 'h', 's', 'N', 'U', '&', 'C', 'j', 'R', 'f', 'S', 'E', 'O', '-', 'z', '8', '4', 'g', 'a', '!', 'q', 'W', 'x', '/', 'T', 'Ã©', '6'}\n"
     ]
    }
   ],
   "source": [
    "print(src_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = set()\n",
    "for line in lines['tar']:\n",
    "    for char in line:\n",
    "        tar_vocab.add(char)\n",
    "        # tar ë¬¸ì ì§‘í•© êµ¬ì¶•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p', '\"', 'L', 'X', 'd', 'Q', ',', 'Ã¹', '0', '9', 'e', '$', 'Ã§', 'Ã¯', '\\n', 'v', '\\xa0', 'Ã‰', 'Ã®', 'V', 't', 'y', '?', 'o', 'F', 'i', '3', '\\u2009', '7', 'Y', 'w', 'G', 'P', '5', 'r', 'Å“', ':', 'k', '.', 'D', 'u', ' ', 'Ã€', 'J', 'l', 'n', 'â€½', 'I', 'H', 'K', '%', 'A', 'b', 'B', '1', '2', 'â€™', 'M', 'm', 'â€˜', 'c', 'Â»', \"'\", 'h', 's', 'Ã¢', 'N', 'U', '&', 'ÃŠ', 'C', 'j', 'R', 'Ã”', 'f', 'Ã‡', 'S', '\\t', 'E', 'O', 'Â«', '-', 'z', '8', '4', 'g', 'a', '!', 'Ãª', 'q', 'Ã ', '\\u202f', 'W', 'x', 'Ã»', 'Ã«', 'T', 'Ã¨', 'Ã´', 'Ã©', '6'}\n"
     ]
    }
   ],
   "source": [
    "print(tar_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src ë¬¸ì¥ì˜ ë¬¸ì ì§‘í•© í¬ê¸° : 80\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(src_vocab) + 1\n",
    "print(f'src ë¬¸ì¥ì˜ ë¬¸ì ì§‘í•© í¬ê¸° : {src_vocab_size}')\n",
    "# ì¸ì½”ë”ì— ë°ì´í„°ë¥¼ ë„£ì„ ë•Œ ì‚¬ìš©ë  ì°¨ì›ì˜ í¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar ë¬¸ì¥ì˜ ë¬¸ì ì§‘í•© í¬ê¸° : 102\n"
     ]
    }
   ],
   "source": [
    "tar_vocab_size = len(tar_vocab) + 1\n",
    "print(f'tar ë¬¸ì¥ì˜ ë¬¸ì ì§‘í•© í¬ê¸° : {tar_vocab_size}')\n",
    "# ë””ì½”ë”ì— ë°ì´í„°ë¥¼ ë„£ì„ ë•Œ ì‚¬ìš©ë  ì°¨ì›ì˜ í¬ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_to_index = {}\n",
    "\n",
    "for i, word in enumerate(src_vocab):\n",
    "    src_to_index[word] = i + 1\n",
    "# ì •ìˆ˜ ì¸ë±ì‹±ì„ ìœ„í•œ ì¸ì½”ë”© ì‘ì—…\n",
    "# íŒ¨ë”©ì„ ìœ„í•œ +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': 1, '\"': 2, 'L': 3, 'X': 4, 'd': 5, ',': 6, 'Q': 7, '0': 8, '9': 9, 'e': 10, '$': 11, 'Ã¯': 12, 'Z': 13, 'v': 14, 'V': 15, 't': 16, '?': 17, 'y': 18, 'o': 19, 'F': 20, 'i': 21, '3': 22, '7': 23, 'Y': 24, 'w': 25, 'G': 26, 'P': 27, '5': 28, 'r': 29, ':': 30, '.': 31, 'k': 32, 'D': 33, 'u': 34, ' ': 35, 'J': 36, 'l': 37, 'n': 38, 'H': 39, 'I': 40, 'K': 41, '%': 42, 'A': 43, 'b': 44, 'â‚¬': 45, 'B': 46, '1': 47, '2': 48, 'â€™': 49, 'M': 50, 'm': 51, 'c': 52, \"'\": 53, 'h': 54, 's': 55, 'N': 56, 'U': 57, '&': 58, 'C': 59, 'j': 60, 'R': 61, 'f': 62, 'S': 63, 'E': 64, 'O': 65, '-': 66, 'z': 67, '8': 68, '4': 69, 'g': 70, 'a': 71, '!': 72, 'q': 73, 'W': 74, 'x': 75, '/': 76, 'T': 77, 'Ã©': 78, '6': 79}\n"
     ]
    }
   ],
   "source": [
    "print(src_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_to_index = {}\n",
    "for i, word in enumerate(tar_vocab):\n",
    "    tar_to_index[word] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p': 1, '\"': 2, 'L': 3, 'X': 4, 'd': 5, 'Q': 6, ',': 7, 'Ã¹': 8, '0': 9, '9': 10, 'e': 11, '$': 12, 'Ã§': 13, 'Ã¯': 14, '\\n': 15, 'v': 16, '\\xa0': 17, 'Ã‰': 18, 'Ã®': 19, 'V': 20, 't': 21, 'y': 22, '?': 23, 'o': 24, 'F': 25, 'i': 26, '3': 27, '\\u2009': 28, '7': 29, 'Y': 30, 'w': 31, 'G': 32, 'P': 33, '5': 34, 'r': 35, 'Å“': 36, ':': 37, 'k': 38, '.': 39, 'D': 40, 'u': 41, ' ': 42, 'Ã€': 43, 'J': 44, 'l': 45, 'n': 46, 'â€½': 47, 'I': 48, 'H': 49, 'K': 50, '%': 51, 'A': 52, 'b': 53, 'B': 54, '1': 55, '2': 56, 'â€™': 57, 'M': 58, 'm': 59, 'â€˜': 60, 'c': 61, 'Â»': 62, \"'\": 63, 'h': 64, 's': 65, 'Ã¢': 66, 'N': 67, 'U': 68, '&': 69, 'ÃŠ': 70, 'C': 71, 'j': 72, 'R': 73, 'Ã”': 74, 'f': 75, 'Ã‡': 76, 'S': 77, '\\t': 78, 'E': 79, 'O': 80, 'Â«': 81, '-': 82, 'z': 83, '8': 84, '4': 85, 'g': 86, 'a': 87, '!': 88, 'Ãª': 89, 'q': 90, 'Ã ': 91, '\\u202f': 92, 'W': 93, 'x': 94, 'Ã»': 95, 'Ã«': 96, 'T': 97, 'Ã¨': 98, 'Ã´': 99, 'Ã©': 100, '6': 101}\n"
     ]
    }
   ],
   "source": [
    "print(tar_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srcë¬¸ì¥ì˜ ì •ìˆ˜ ì¸ì½”ë”© [[26, 19, 31], [26, 19, 31], [26, 19, 31], [26, 19, 31], [39, 21, 31]]\n"
     ]
    }
   ],
   "source": [
    "encoder_input = []\n",
    "for line in lines['src']:\n",
    "    encoded_line = []\n",
    "    for char in line:\n",
    "        encoded_line.append(src_to_index[char])\n",
    "    encoder_input.append(encoded_line)\n",
    "print(f'srcë¬¸ì¥ì˜ ì •ìˆ˜ ì¸ì½”ë”© {encoder_input[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tarë¬¸ì¥ì˜ ì •ìˆ˜ ì¸ì½”ë”© [[78, 42, 20, 87, 42, 88, 42, 15], [78, 42, 58, 87, 35, 61, 64, 11, 39, 42, 15], [78, 42, 79, 46, 42, 35, 24, 41, 21, 11, 42, 88, 42, 15], [78, 42, 54, 24, 41, 86, 11, 42, 88, 42, 15], [78, 42, 77, 87, 45, 41, 21, 42, 88, 42, 15]]\n"
     ]
    }
   ],
   "source": [
    "decoder_input = []\n",
    "for line in lines['tar']:\n",
    "    decoded_line = []\n",
    "    for char in line:\n",
    "        decoded_line.append(tar_to_index[char])\n",
    "    decoder_input.append(decoded_line)\n",
    "print(f'tarë¬¸ì¥ì˜ ì •ìˆ˜ ì¸ì½”ë”© {decoder_input[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë””ì½”ë” target ë¬¸ì¥ì˜ ì •ë¶€ ì¸ì½”ë”© [[42, 20, 87, 42, 88, 42, 15], [42, 58, 87, 35, 61, 64, 11, 39, 42, 15], [42, 79, 46, 42, 35, 24, 41, 21, 11, 42, 88, 42, 15], [42, 54, 24, 41, 86, 11, 42, 88, 42, 15], [42, 77, 87, 45, 41, 21, 42, 88, 42, 15]]\n"
     ]
    }
   ],
   "source": [
    "decoder_target = []\n",
    "for line in lines['tar']:\n",
    "    char_position = 0\n",
    "    # ë¬¸ì ìœ„ì¹˜ë¥¼ ì¶”ì í•  ìˆ˜ ìˆëŠ” ë³€ìˆ˜\n",
    "    decoded_line = []\n",
    "    for char in line:\n",
    "        if char_position != 0:\n",
    "            decoded_line.append(tar_to_index[char])\n",
    "        char_position = char_position+1\n",
    "    decoder_target.append(decoded_line)\n",
    "print(f'ë””ì½”ë” target ë¬¸ì¥ì˜ ì •ë¶€ ì¸ì½”ë”© {decoder_target[:5]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ : 22\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for line in lines['src']:\n",
    "    lengths.append(len(line))\n",
    "max_src_len = max(lengths)\n",
    "print(f'src ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ : {max_src_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ : 76\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for line in lines['tar']:\n",
    "    lengths.append(len(line))\n",
    "max_tar_len = max(lengths)\n",
    "print(f'tar ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ : {max_tar_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
    "# ì¸ì½”ë”ì— ë“¤ì–´ê°ˆ ë°ì´í„° íŒ¨ë”© ì‘ì—…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding = 'post')\n",
    "# ë””ì½”ë”ì— ë“¤ì–´ê°ˆ ë°ì´í„° íŒ¨ë”© ì‘ì—…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')\n",
    "# ë””ì½”ë”ì˜ ì •ë‹µ ë°ì´í„°ë¡œ ì‚¬ìš©ë  ë°ì´í„° íŒ¨ë”© ì‘ì—…\n",
    "\n",
    "# 1. ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ë¬¸ì¥ ê¸¸ì´ëŠ” ë™ì¼í•˜ê²Œ ë§ì¶”ì§€ ì•Šì•„ë„ ëœë‹¤\n",
    "# - ì¸ì½”ë” ë°ì´í„°ëŠ” ì¸ì½”ë” ë°ì´í„°ë¼ë¦¬, ë””ì½”ë” ë°ì´í„°ëŠ” ë””ì½”ë” ë°ì´í„°ë¼ë¦¬ ë§ì¶”ì–´ íŒ¨ë”©í•˜ë©´ ëœë‹¤\n",
    "# 2. íŒ¨ë”©ì„ ì•ì— ë‘˜ê¹Œ, ë’¤ì— ë‘˜ê¹Œ?\n",
    "# - ë¬¸ì¥ ìƒì„± ì‹œì—ëŠ” ë¬¸ì¥ ëì— ì–´ë–¤ ë‹¨ì–´ê°€ ë‚˜ì˜¬ì§€ê°€ ë” ì¤‘ìš”í•˜ê¸° ë•Œë¬¸ì— íŒ¨ë”©ì„ ì•ì— ë‘ê³ \n",
    "# - ë¬¸ì¥ì˜ ìˆœì„œ, ì‹œí€€ìŠ¤ë¥¼ ìœ ì§€í•˜ëŠ” ë” ì¤‘ìš”í•œ ê²½ìš°ì—ëŠ” íŒ¨ë”©ì„ ë’¤ìª½ì— ë‘”ë‹¤\n",
    "# 3. ë””ì½”ë”ì˜ targetë°ì´í„°ì—ì„œëŠ” <sos>ê°€ ì œê±°ë˜ì—ˆëŠ”ë° ë™ì¼í•˜ê²Œ íŒ¨ë”©ì„ ì£¼ì–´ë„ ë˜ëŠ”ê°€?\n",
    "# - íŒ¨ë”©ì€ ë¶€ì¡±í•œ ë¶€ë¶„ì„ 0ì„ ì±„ì›Œ ë™ì¼í•œ ê¸¸ì´ë¡œ ë§ì¶”ëŠ” ê³¼ì •ì´ê¸° ë•Œë¬¸ì—, targetê³¼ decoderì˜ ê¸¸ì´ ì°¨ì´ëŠ” ì¤‘ìš”í•˜ì§€ ì•Šë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = to_categorical(encoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = to_categorical(decoder_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target = to_categorical(decoder_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape = (None, src_vocab_size))\n",
    "# (None, src_vocab_size)ì˜ í˜•íƒœë¥¼ ê°–ëŠ” ì¸í’‹ì„ ì£¼ê² ë‹¤\n",
    "# None : ê°€ë³€ì ì¸ ì…ë ¥ ë¬¸ì¥ì˜ ê¸¸ì´\n",
    "# abc, de\n",
    "# [[0,0,1],[0,1,0],[1,0,0]] # abc\n",
    "# [[1,0,1], [1,1,1]] #de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_lstm = LSTM(units=256, return_state=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# LSTMì€ ì€ë‹‰ ìƒíƒœì™€ ì…€ ìƒíƒœë¥¼ ë¦¬í„´í•œë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_states = [state_h, state_c]\n",
    "# context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape = (None, tar_vocab_size))\n",
    "# ë””ì½”ë”ëŠ” ì¸ì½”ë”ì˜ context vectorë¥¼ ì´ˆê¸° ì€ë‹‰ ìƒíƒœë¡œ ì‚¬ìš©í•œë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
    "# return_sequences : ëª¨ë“  íƒ€ì„ìŠ¤í…ì˜ ì¶œë ¥\n",
    "# return_state : ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì€ë‹‰ìƒíƒœì™€ ì…€ìƒíƒœë¥¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "# ë””ì½”ë”ì˜ outputs ì¶œë ¥ë˜ëŠ” êµ¬ê°„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
    "# ë””ì½”ë”ì˜ ì¶œë ¥ì€ íƒ€ê²Ÿ ë‹¨ì–´ ì§‘í•©ì˜ ê° ë‹¨ì–´ì— ëŒ€í•œ í™•ë¥  ì¤‘ ë†’ì€ ê°’ì´ì–´ì•¼í•œë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "# ëª¨ë¸ì— ì…ë ¥í•  ë°ì´í„°ì˜ í˜•íƒœ\n",
    "model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 248s 326ms/step - loss: 0.7183 - val_loss: 0.6322\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 268s 357ms/step - loss: 0.4389 - val_loss: 0.5080\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 252s 336ms/step - loss: 0.3679 - val_loss: 0.4485\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 212s 283ms/step - loss: 0.3272 - val_loss: 0.4142\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 218s 291ms/step - loss: 0.2998 - val_loss: 0.3894\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 262s 349ms/step - loss: 0.2795 - val_loss: 0.3739\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 277s 369ms/step - loss: 0.2637 - val_loss: 0.3600\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 272s 362ms/step - loss: 0.2509 - val_loss: 0.3546\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 276s 369ms/step - loss: 0.2401 - val_loss: 0.3471\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 253s 337ms/step - loss: 0.2308 - val_loss: 0.3408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x247f7d3a9d0>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = [encoder_input, decoder_input],\n",
    "    # ëª¨ë¸ì— ì…ë ¥í•  ë°ì´í„°\n",
    "    y = decoder_target,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²ˆì—­ ë™ì‘ step\n",
    "# 1. ë²ˆì—­í•˜ë ¤ê³  í•˜ëŠ” inputë¬¸ì¥ì´ ì¸ì½”ë”ì— ë“¤ì–´ê°€ì„œ contextë²¡í„°ë¥¼ ì–»ëŠ”ë‹¤\n",
    "# 2. contextë²¡í„°ì™€ <sos> (\\t)ë¥¼ ë””ì½”ë”ë¡œ ë³´ë‚¸ë‹¤\n",
    "# 3. ë””ì½”ë”ê°€ <eos> (\\n)ì´ ë‚˜ì˜¬ ë–„ ê¹Œì§€ ë‹¤ìŒ ë¬¸ìë¥¼ ì˜ˆì¸¡ ë°˜ë³µ\n",
    "\n",
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape = (256, )) # ì€ë‹‰ ìƒíƒœ\n",
    "decoder_state_input_c = Input(shape = (256,)) # ì…€ìƒíƒœ\n",
    "\n",
    "# ë””ì½”ë” ì…€ì—ì„œ ê°ê° ì´ì „ ì‹œì ì˜ ìƒíƒœë¥¼ ì €ì¥í•˜ëŠ” í…ì„œ\n",
    "# ë””ì½”ë”ì˜ ì€ë‹‰ ìƒíƒœì™€ ì…€ ìƒíƒœë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê¸° ìœ„í•œ í…ì„œë¡œ, ë””ì½”ë” LSTMì˜ hidden unitsí¬ê¸°ì™€ ë™ì¼í•˜ê²Œ ë„£ì–´ì£¼ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# ë””ì½”ë” lstmëª¨ë¸ì´ ì…ë ¥ê°’ì¸ decoder_inputsì™€, ì´ì „ ìƒíƒœì¸ decoder_States_inputsë¥¼ ì…ë ¥ ë°›ì•„\n",
    "# ë‹¤ìŒ ë‹¨ì–´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ì¶œë ¥(decoder_outputs)ì™€ ìƒˆë¡œìš´ ì€ë‹‰ìƒíƒœ/ì…€ ìƒíƒœ(state_h, state_c)ë¥¼ ê³„ì‚°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "# ë””ì½”ë” ì¶œë ¥ê°’ì„ ì†Œí”„íŠ¸ë§¥ìŠ¤ ë ˆì´ì–´ë¡œ í†µê³¼ì‹œì¼œ ë‹¨ì–´ë³„ í™•ë¥  ë¶„í¬ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(inputs = [decoder_inputs] + decoder_states_inputs, outputs= [decoder_outputs] + decoder_states)\n",
    "# ë‹¤ìŒ ë‹¨ì–´ì˜ í™•ë¥  ë¶„í¬ì™€ ìƒˆë¡œìš´ ìƒíƒœê°’ì„ ë°˜í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'p', 2: '\"', 3: 'L', 4: 'X', 5: 'd', 6: ',', 7: 'Q', 8: '0', 9: '9', 10: 'e', 11: '$', 12: 'Ã¯', 13: 'Z', 14: 'v', 15: 'V', 16: 't', 17: '?', 18: 'y', 19: 'o', 20: 'F', 21: 'i', 22: '3', 23: '7', 24: 'Y', 25: 'w', 26: 'G', 27: 'P', 28: '5', 29: 'r', 30: ':', 31: '.', 32: 'k', 33: 'D', 34: 'u', 35: ' ', 36: 'J', 37: 'l', 38: 'n', 39: 'H', 40: 'I', 41: 'K', 42: '%', 43: 'A', 44: 'b', 45: 'â‚¬', 46: 'B', 47: '1', 48: '2', 49: 'â€™', 50: 'M', 51: 'm', 52: 'c', 53: \"'\", 54: 'h', 55: 's', 56: 'N', 57: 'U', 58: '&', 59: 'C', 60: 'j', 61: 'R', 62: 'f', 63: 'S', 64: 'E', 65: 'O', 66: '-', 67: 'z', 68: '8', 69: '4', 70: 'g', 71: 'a', 72: '!', 73: 'q', 74: 'W', 75: 'x', 76: '/', 77: 'T', 78: 'Ã©', 79: '6'}\n"
     ]
    }
   ],
   "source": [
    "index_to_src = {}\n",
    "for char, i in src_to_index.items():\n",
    "    index_to_src[i] = char\n",
    "    # key : ì •ìˆ˜ ì¸ë±ìŠ¤, valueê°€ ë¬¸ìë¡œ ë˜ë„ë¡ ë’¤ì§‘ì–´ì£¼ê¸°\n",
    "\n",
    "print(index_to_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'p', 2: '\"', 3: 'L', 4: 'X', 5: 'd', 6: 'Q', 7: ',', 8: 'Ã¹', 9: '0', 10: '9', 11: 'e', 12: '$', 13: 'Ã§', 14: 'Ã¯', 15: '\\n', 16: 'v', 17: '\\xa0', 18: 'Ã‰', 19: 'Ã®', 20: 'V', 21: 't', 22: 'y', 23: '?', 24: 'o', 25: 'F', 26: 'i', 27: '3', 28: '\\u2009', 29: '7', 30: 'Y', 31: 'w', 32: 'G', 33: 'P', 34: '5', 35: 'r', 36: 'Å“', 37: ':', 38: 'k', 39: '.', 40: 'D', 41: 'u', 42: ' ', 43: 'Ã€', 44: 'J', 45: 'l', 46: 'n', 47: 'â€½', 48: 'I', 49: 'H', 50: 'K', 51: '%', 52: 'A', 53: 'b', 54: 'B', 55: '1', 56: '2', 57: 'â€™', 58: 'M', 59: 'm', 60: 'â€˜', 61: 'c', 62: 'Â»', 63: \"'\", 64: 'h', 65: 's', 66: 'Ã¢', 67: 'N', 68: 'U', 69: '&', 70: 'ÃŠ', 71: 'C', 72: 'j', 73: 'R', 74: 'Ã”', 75: 'f', 76: 'Ã‡', 77: 'S', 78: '\\t', 79: 'E', 80: 'O', 81: 'Â«', 82: '-', 83: 'z', 84: '8', 85: '4', 86: 'g', 87: 'a', 88: '!', 89: 'Ãª', 90: 'q', 91: 'Ã ', 92: '\\u202f', 93: 'W', 94: 'x', 95: 'Ã»', 96: 'Ã«', 97: 'T', 98: 'Ã¨', 99: 'Ã´', 100: 'Ã©', 101: '6'}\n"
     ]
    }
   ],
   "source": [
    "index_to_tar = {}\n",
    "for char, i in tar_to_index.items():\n",
    "    index_to_tar[i] = char\n",
    "\n",
    "print(index_to_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    # (1, 1, tar_vocab_size) ë°°ì—´ ìƒì„±\n",
    "    target_seq[0, 0, tar_to_index['\\t']] = 1\n",
    "    # 0ë²ˆì§¸ ë¬¸ì¥ì˜ 0ë²ˆì§¸ ë‹¨ì–´ì˜ \\tì— í•´ë‹¹í•˜ëŠ” ìœ„ì¹˜ë¥¼ 1ë¡œ ì„¤ì •\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        # target_seq : í˜„ì¬ ë””ì½”ë”ì˜ ì…ë ¥ ì‹œí€€ìŠ¤\n",
    "        # states_value : context vector\n",
    "        # output_tokens : ë‹¤ìŒ ë‹¨ì–´ì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥  ë¶„í¬, h : ì€ë‹‰ ìƒíƒœ, c : ì…€ ìƒíƒœ\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        # ì˜ˆì¸¡ëœ ë°ì´í„° ì¤‘ì—ì„œ í˜„ì¬ íƒ€ì„ ìŠ¤í…ì˜ ë§ˆì§€ë§‰ ê°’ì„ ë¶ˆëŸ¬ì™€ì„œ ê·¸ ì¤‘ì— argmax(ìµœëŒ€ê°’)ì„ sample_token_indexì— ì €ì¥\n",
    "        sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n",
    "            stop_condition = True\n",
    "            # eosì— ë„ë‹¬í•˜ê±°ë‚˜ ìµœëŒ€ ë¬¸ì¥ ê¸¸ì´ë¥¼ ë„˜ì–´ì„œë©´ ë°˜ë³µì„ ì¤‘ë‹¨\n",
    "\n",
    "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "        # 1, 1, tar_vocab_sizeì˜ ë°°ì—´ ìƒì„±\n",
    "        #(ë°°ì¹˜ì‚¬ì´ì¦ˆ, ì‹œí€€ìŠ¤ ê¸¸ì´, íƒ€ê²Ÿ ì§‘í•©ì˜ í¬ê¸°)\n",
    "        target_seq[0, 0, sampled_token_index] = 1\n",
    "        # ì²«ë²ˆì§¸ ë°°ì¹˜, ì²«ë²ˆì§¸ íƒ€ì„ìŠ¤í…ì—ì„œ sampled_token_indexì— í•´ë‹¹í•˜ëŠ” ìœ„ì¹˜ë¥¼ 1ë¡œ ì„¤ì •\n",
    "\n",
    "        states_value = [h, c]\n",
    "        # í˜„ì¬ ì‹œì ì˜ ìƒíƒœë¥¼ ë‹¤ìŒ ì‹œì ì˜ ìƒíƒœë¡œ ì „ë‹¬\n",
    "        \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "ì…ë ¥ ë¬¸ì¥ : Be brief.\n",
      "ì •ë‹µ ë¬¸ì¥ : Soyez brefs. \n",
      "ë²ˆì—­ ë¬¸ì¥ : Soyez prudente ! \n",
      "\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "ì…ë ¥ ë¬¸ì¥ : Forget it.\n",
      "ì •ë‹µ ë¬¸ì¥ : Oubliez Ã§a ! \n",
      "ë²ˆì—­ ë¬¸ì¥ : Oubliez-le. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [500, 1000]:\n",
    "    input_seq = encoder_input[seq_index:seq_index +1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(f'ì…ë ¥ ë¬¸ì¥ : {lines.src[seq_index]}')\n",
    "    print(f'ì •ë‹µ ë¬¸ì¥ : {lines.tar[seq_index][2:len(lines.tar[seq_index])-1]}')\n",
    "    print(f'ë²ˆì—­ ë¬¸ì¥ : {decoded_sentence[1:len(decoded_sentence)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
