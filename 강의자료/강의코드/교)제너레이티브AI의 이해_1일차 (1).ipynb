{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸŒ¼ ì œë„ˆë ˆì´í‹°ë¸ŒAIì˜ ì´í•´ - 1ì°¨ì‹œ(24.11.18)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VAE(Variational Auto Encoder)\n",
    "- ëª¨ë¸ì´ ìˆ«ì ì´ë¯¸ì§€ë¥¼ ì••ì¶•í•˜ê³ , ë³µì›í•˜ëŠ” ê³¼ì •(ì¸ì½”ë”-ë””ì½”ë”)\n",
    "- ì¸ì½”ë” : ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì ì¬ê³µê°„ìœ¼ë¡œ ë§¤í•‘\n",
    "- ë””ì½”ë” : ì ì¬ ê³µê°„ì—ì„œ ìƒ˜í”Œì„ ë°›ì•„ ì´ë¯¸ì§€ ë³µì›\n",
    "- ê°€ìƒí™˜ê²½ ì‹¤í–‰ í›„ - pip install opencv-pythonë¡œ ì„¤ì¹˜!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflowë¥¼ í™œìš©í•œ celebë°ì´í„°ì…‹ì— VAE ì ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays_v1.py:37: UserWarning: A NumPy version >=1.22.4 and <2.3.0 is required for this version of SciPy (detected version 1.21.6)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\RMARKET\\.cache\\kagglehub\\datasets\\yunting0123\\img-align-celeba\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"yunting0123/img-align-celeba\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "image_dir = \"C:/Users/RMARKET/.cache/kagglehub/datasets/yunting0123/img-align-celeba/versions/1/t/celebA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'030000.png'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_filenames = os.listdir(image_dir)[-1]\n",
    "img_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê³  ì „ì²˜ë¦¬ í•˜ëŠ” í•¨ìˆ˜ ë§Œë“¤ê¸°\n",
    "def load_preprocess_images(image_dir, img_size = (128, 128), num_images = 10000):\n",
    "    # ê²½ë¡œ, ì´ë¯¸ì§€ í¬ê¸°, ìµœëŒ€ ë¡œë“œí•  ì´ë¯¸ì§€ ê°œìˆ˜\n",
    "    images = []\n",
    "    # ì „ì²˜ë¦¬ ëœ ì´ë¯¸ì§€ë¥¼ ì¶”ê°€í•  ë¦¬ìŠ¤íŠ¸\n",
    "    img_filenames = os.listdir(image_dir)[:num_images]\n",
    "    for filename in img_filenames:\n",
    "        img_path = os.path.join(image_dir, filename)\n",
    "        # ì´ë¯¸ì§€ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ image_dir(í´ë” ê²½ë¡œ) + filename(íŒŒì¼ ì´ë¦„)ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê¸°\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is not None : \n",
    "            img = cv2.resize(img, img_size)\n",
    "            img = img / 255.0\n",
    "            # ì´ë¯¸ì§€ ì •ê·œí™”\n",
    "            # [204, 76, 128] -> [0.8, 0.3, 0.5]\n",
    "            images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.78823529, 0.88627451, 0.94901961],\n",
       "         [0.84705882, 0.92156863, 0.96862745],\n",
       "         [0.87843137, 0.9372549 , 0.98039216]],\n",
       "\n",
       "        [[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.79607843, 0.89411765, 0.95294118],\n",
       "         [0.85098039, 0.92156863, 0.97254902],\n",
       "         [0.87843137, 0.9372549 , 0.98039216]],\n",
       "\n",
       "        [[0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         [0.75294118, 0.90588235, 0.99215686],\n",
       "         ...,\n",
       "         [0.81960784, 0.90588235, 0.96078431],\n",
       "         [0.85490196, 0.9254902 , 0.97647059],\n",
       "         [0.8745098 , 0.93333333, 0.98431373]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.23529412, 0.40392157, 0.6745098 ],\n",
       "         [0.22745098, 0.39215686, 0.6627451 ],\n",
       "         [0.21176471, 0.37254902, 0.63921569],\n",
       "         ...,\n",
       "         [0.0627451 , 0.16078431, 0.40784314],\n",
       "         [0.0627451 , 0.16078431, 0.40392157],\n",
       "         [0.0627451 , 0.16078431, 0.40392157]],\n",
       "\n",
       "        [[0.2       , 0.36078431, 0.63921569],\n",
       "         [0.20784314, 0.37254902, 0.64705882],\n",
       "         [0.22745098, 0.39215686, 0.67058824],\n",
       "         ...,\n",
       "         [0.07843137, 0.18039216, 0.43921569],\n",
       "         [0.0745098 , 0.18039216, 0.43529412],\n",
       "         [0.0745098 , 0.18039216, 0.43529412]],\n",
       "\n",
       "        [[0.18039216, 0.34117647, 0.61960784],\n",
       "         [0.19607843, 0.36078431, 0.63921569],\n",
       "         [0.23137255, 0.4       , 0.68235294],\n",
       "         ...,\n",
       "         [0.08627451, 0.18823529, 0.45490196],\n",
       "         [0.08235294, 0.18823529, 0.45098039],\n",
       "         [0.08235294, 0.18823529, 0.45098039]]],\n",
       "\n",
       "\n",
       "       [[[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28235294, 0.29803922],\n",
       "         [0.28235294, 0.30196078, 0.31764706],\n",
       "         [0.29019608, 0.31372549, 0.3254902 ]],\n",
       "\n",
       "        [[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28235294, 0.29803922],\n",
       "         [0.28235294, 0.30588235, 0.31764706],\n",
       "         [0.29019608, 0.31372549, 0.3254902 ]],\n",
       "\n",
       "        [[0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         [0.18039216, 0.2       , 0.25882353],\n",
       "         ...,\n",
       "         [0.27058824, 0.28627451, 0.29803922],\n",
       "         [0.28627451, 0.30588235, 0.31764706],\n",
       "         [0.29411765, 0.31764706, 0.32941176]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.80784314, 0.78431373, 0.77647059],\n",
       "         [0.81176471, 0.79215686, 0.78431373],\n",
       "         [0.82745098, 0.80392157, 0.8       ],\n",
       "         ...,\n",
       "         [0.4       , 0.41960784, 0.53333333],\n",
       "         [0.45882353, 0.47058824, 0.55686275],\n",
       "         [0.48627451, 0.49803922, 0.57254902]],\n",
       "\n",
       "        [[0.85882353, 0.83529412, 0.83529412],\n",
       "         [0.85490196, 0.83529412, 0.83529412],\n",
       "         [0.85098039, 0.83137255, 0.83137255],\n",
       "         ...,\n",
       "         [0.38039216, 0.40784314, 0.52941176],\n",
       "         [0.43137255, 0.45098039, 0.54901961],\n",
       "         [0.45882353, 0.47058824, 0.56078431]],\n",
       "\n",
       "        [[0.88235294, 0.8627451 , 0.86666667],\n",
       "         [0.8745098 , 0.85490196, 0.85882353],\n",
       "         [0.8627451 , 0.84313725, 0.84705882],\n",
       "         ...,\n",
       "         [0.37254902, 0.4       , 0.5254902 ],\n",
       "         [0.41960784, 0.43921569, 0.54509804],\n",
       "         [0.44313725, 0.45882353, 0.55294118]]],\n",
       "\n",
       "\n",
       "       [[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.22352941, 0.34117647, 0.51764706],\n",
       "         [0.21960784, 0.34509804, 0.5254902 ],\n",
       "         [0.21568627, 0.36078431, 0.54117647],\n",
       "         ...,\n",
       "         [0.25098039, 0.23921569, 0.23921569],\n",
       "         [0.25490196, 0.24313725, 0.24705882],\n",
       "         [0.25882353, 0.24705882, 0.25098039]],\n",
       "\n",
       "        [[0.22745098, 0.32156863, 0.48235294],\n",
       "         [0.22352941, 0.3254902 , 0.49019608],\n",
       "         [0.21568627, 0.34509804, 0.51372549],\n",
       "         ...,\n",
       "         [0.24313725, 0.23529412, 0.23921569],\n",
       "         [0.24705882, 0.23921569, 0.24313725],\n",
       "         [0.25098039, 0.24313725, 0.24705882]],\n",
       "\n",
       "        [[0.22745098, 0.30980392, 0.4627451 ],\n",
       "         [0.22352941, 0.31764706, 0.4745098 ],\n",
       "         [0.21960784, 0.3372549 , 0.49803922],\n",
       "         ...,\n",
       "         [0.23921569, 0.23137255, 0.23529412],\n",
       "         [0.24313725, 0.23529412, 0.23921569],\n",
       "         [0.24705882, 0.23921569, 0.24313725]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.71372549, 0.69411765, 0.69803922],\n",
       "         [0.71764706, 0.69803922, 0.70196078],\n",
       "         [0.72941176, 0.70980392, 0.71372549],\n",
       "         ...,\n",
       "         [0.75294118, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.72941176],\n",
       "         [0.74901961, 0.72941176, 0.72941176]],\n",
       "\n",
       "        [[0.70588235, 0.68627451, 0.69019608],\n",
       "         [0.70980392, 0.69019608, 0.69411765],\n",
       "         [0.72156863, 0.70196078, 0.70588235],\n",
       "         ...,\n",
       "         [0.75294118, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.73333333],\n",
       "         [0.74901961, 0.72941176, 0.72941176]],\n",
       "\n",
       "        [[0.68627451, 0.66666667, 0.67058824],\n",
       "         [0.69019608, 0.67058824, 0.6745098 ],\n",
       "         [0.70588235, 0.68627451, 0.69019608],\n",
       "         ...,\n",
       "         [0.74901961, 0.72941176, 0.73333333],\n",
       "         [0.74901961, 0.73333333, 0.73333333],\n",
       "         [0.74901961, 0.73333333, 0.73333333]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.78823529, 0.76862745, 0.76470588],\n",
       "         [0.78823529, 0.76862745, 0.76470588],\n",
       "         [0.78823529, 0.76862745, 0.76470588],\n",
       "         ...,\n",
       "         [0.87058824, 0.8627451 , 0.87843137],\n",
       "         [0.8745098 , 0.86666667, 0.87843137],\n",
       "         [0.87843137, 0.86666667, 0.87843137]],\n",
       "\n",
       "        [[0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         ...,\n",
       "         [0.87058824, 0.86666667, 0.88235294],\n",
       "         [0.87843137, 0.86666667, 0.87843137],\n",
       "         [0.88235294, 0.87058824, 0.87843137]],\n",
       "\n",
       "        [[0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         [0.79215686, 0.77254902, 0.76862745],\n",
       "         ...,\n",
       "         [0.8745098 , 0.86666667, 0.88235294],\n",
       "         [0.87843137, 0.87058824, 0.87843137],\n",
       "         [0.88235294, 0.87058824, 0.87843137]]],\n",
       "\n",
       "\n",
       "       [[[0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        [[0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         [0.52156863, 0.49019608, 0.42352941],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        [[0.5254902 , 0.49411765, 0.42745098],\n",
       "         [0.5254902 , 0.49411765, 0.42745098],\n",
       "         [0.5254902 , 0.49411765, 0.42745098],\n",
       "         ...,\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882],\n",
       "         [0.54509804, 0.51372549, 0.44705882]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.92156863, 0.94509804, 0.94509804],\n",
       "         [0.91764706, 0.9372549 , 0.94117647],\n",
       "         [0.90196078, 0.9254902 , 0.92941176],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54117647, 0.49803922, 0.44313725]],\n",
       "\n",
       "        [[0.93333333, 0.94901961, 0.94901961],\n",
       "         [0.9254902 , 0.94117647, 0.94509804],\n",
       "         [0.91372549, 0.92941176, 0.93333333],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882]],\n",
       "\n",
       "        [[0.9372549 , 0.95294118, 0.95294118],\n",
       "         [0.92941176, 0.94509804, 0.94509804],\n",
       "         [0.91764706, 0.93333333, 0.93333333],\n",
       "         ...,\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882],\n",
       "         [0.54509804, 0.50196078, 0.44705882]]],\n",
       "\n",
       "\n",
       "       [[[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        [[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        [[0.8       , 0.77254902, 0.76078431],\n",
       "         [0.80392157, 0.77647059, 0.76470588],\n",
       "         [0.81568627, 0.78823529, 0.77647059],\n",
       "         ...,\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294],\n",
       "         [0.88235294, 0.88235294, 0.88235294]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.83529412, 0.83921569, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.81568627, 0.81960784, 0.81960784],\n",
       "         ...,\n",
       "         [0.2       , 0.26666667, 0.38039216],\n",
       "         [0.19607843, 0.26666667, 0.38039216],\n",
       "         [0.19215686, 0.26666667, 0.38431373]],\n",
       "\n",
       "        [[0.83137255, 0.83529412, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.82352941, 0.82352941, 0.82352941],\n",
       "         ...,\n",
       "         [0.17647059, 0.23529412, 0.35294118],\n",
       "         [0.17647059, 0.23921569, 0.36078431],\n",
       "         [0.18039216, 0.24313725, 0.36470588]],\n",
       "\n",
       "        [[0.83137255, 0.83529412, 0.83137255],\n",
       "         [0.82745098, 0.83137255, 0.82745098],\n",
       "         [0.82352941, 0.82745098, 0.82352941],\n",
       "         ...,\n",
       "         [0.16470588, 0.21960784, 0.3372549 ],\n",
       "         [0.16862745, 0.22745098, 0.34901961],\n",
       "         [0.17254902, 0.23137255, 0.35294118]]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = load_preprocess_images(image_dir)\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ìƒ˜í”Œë§ í•¨ìˆ˜ ì •ì˜\n",
    "# ì ì¬ê³µê°„ì—ì„œ ìƒˆë¡œìš´ ìƒ˜í”Œì„ ìƒì„±í•˜ê¸° ìœ„í•´ ë°ì´í„°í¬ì¸íŠ¸ë“¤ì„ ìƒ˜í”Œë§í•˜ëŠ” ê³¼ì •\n",
    "# ê° ë°ì´í„°í¬ì¸í„°ë“¤ì˜ í‰ê· ê°’ê³¼ ë¡œê·¸ë¶„ì‚°ì„ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\n",
    "def sampling(z_mean, z_log_var):\n",
    "    # ëª¨ë¸ì´ ìƒˆë¡œìš´ ë°ì´í„°í¬ì¸íŠ¸(z)ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŒ\n",
    "    batch = tf.shape(z_mean)[0]\n",
    "    # ë”¥ëŸ¬ë‹í”„ë ˆì„ì›Œí¬ëŠ” ë°ì´í„° ì…ë ¥ ì‹œ ìë™ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸°ë¥¼ ê°ì§€\n",
    "    # 0ë²ˆì§¸ ìë¦¬ì˜ ê°’ì´ batchì‚¬ì´ì¦ˆì´ë¯€ë¡œ batchë¼ëŠ” ì´ë¦„ì˜ ë³€ìˆ˜ë¡œ ì €ì¥í•œ ê²ƒ\n",
    "\n",
    "    dim = tf.shape(z_mean)[1]\n",
    "    # ì ì¬ê³µê°„ì˜ ì°¨ì›ê°’\n",
    "\n",
    "    epsilon = tf.random.normal(shape = (batch, dim))\n",
    "    # ë°°ì¹˜ì‚¬ì´ì¦ˆì™€ ì°¨ì›ì˜ shapeì„ ê°–ëŠ” í‘œì¤€ì •ê·œë¶„í¬ì˜ ë¬´ì‘ìœ„ê°’ ìƒì„±\n",
    "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "# tf.exp(0.5 * z_log_var) -> ë¡œê·¸ ë¶„ì‚°ì„ í‘œì¤€í¸ì°¨ë¡œ ë³€í™˜í•˜ëŠ” ê³¼ì •, ë¡œê·¸ë¶„ì‚°ì— 0.5ë¥¼ ê³±í•˜ê³  ì§€ìˆ˜í•¨ìˆ˜ë¥¼ ì ìš©\n",
    "# -> í‘œì¤€í¸ì°¨ë¥¼ êµ¬í•¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ì¸ì½”ë” ì •ì˜\n",
    "latent_dim = 200\n",
    "# ì ì¬ ê³µê°„ì˜ ì°¨ì›\n",
    "# ê°„ë‹¨í•œ ë°ì´í„°ë‚˜ í…ŒìŠ¤íŠ¸ ëª©ì  : 2~10ì •ë„\n",
    "# ë³µì¡í•œ ì´ë¯¸ì§€ë‚˜ ê³ ì°¨ì› : 100~200 ì‚¬ìš©\n",
    "\n",
    "encoder_input = keras.layers.Input(shape = (128, 128, 3), name='encoder_input')\n",
    "# 128x128 ì‚¬ì´ì¦ˆì˜ ì»¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ ì¸í’‹ìœ¼ë¡œ ë„£ì„ ê²ƒì„ì„ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•œ ê²ƒ\n",
    "x = keras.layers.Conv2D(32, (3, 3), strides = 2, activation='relu', padding = 'same')(encoder_input)\n",
    "# Conv2D : ê³µê°„ì ì¸ íŒ¨í„´ í•™ìŠµ ê°€ëŠ¥\n",
    "# 32ê°œ í•„í„°, (3,3)ì»¤ë„, ìŠ¬ë¼ì´ë”©ê°„ê²© 2\n",
    "x = keras.layers.Conv2D(64, (3, 3), strides = 2, activation = 'relu', padding = 'same')(x)\n",
    "x = keras.layers.Conv2D(128, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "# x.shape = (batch_size, height, width, channels)\n",
    "shape_before_flattening = x.shape[1:]\n",
    "# xë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸° ì „ ì •ë³´ ì €ì¥\n",
    "\n",
    "# 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ : Conv2DëŠ” ì´ë¯¸ì§€ì˜ ê³µê°„ì ì¸ êµ¬ì¡°ë¥¼ í•™ìŠµí•  ìˆ˜ ìˆìœ¼ë‚˜ ê²°ì •ì„ ë‚´ë¦´ ìˆœ ì—†ìŒ\n",
    "# ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆëŠ” Denseì¸µì„ ìŒ“ì•„ì£¼ê¸° ìœ„í•´ 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ (flatten, í‰íƒ„í™”)\n",
    "x = keras.layers.Flatten()(x)\n",
    "\n",
    "# ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ ë‹¨ê³„\n",
    "z_mean = keras.layers.Dense(latent_dim, name = 'z_mean')(x)\n",
    "z_log_var = keras.layers.Dense(latent_dim, name = 'z_log_var')(x)\n",
    "# ë‘ ë ˆì´ì–´ëŠ” ë™ì¼í•œ ì…ë ¥ xë¥¼ ë°›ì§€ë§Œ, ì†ì‹¤í•¨ìˆ˜ì™€ ì—­ì „íŒŒ ê³¼ì •ì— ì˜í•´ ë‹¤ë¥¸ ì¶œë ¥ì„ í•™ìŠµ\n",
    "\n",
    "z = sampling(z_mean, z_log_var)\n",
    "# ë¬´ì‘ìœ„ ë²¡í„°ê°’ ìƒì„±\n",
    "\n",
    "encoder = keras.models.Model(encoder_input, [z_mean, z_log_var, z], name = 'encoder')\n",
    "# ëª¨ë¸ì€ ì„¸ ê°œì˜ ì¶œë ¥ì„ ë°˜í™˜í•œë‹¤\n",
    "# z_mean : ì¸ì½”ë”ê°€ í•™ìŠµí•œ ì ì¬ ê³µê°„ì˜ í‰ê·  ë²¡í„°\n",
    "# z_log_var : ì¸ì½”ë”ê°€ í•™ìŠµí•œ ë¡œê·¸ ë¶„ì‚° ë²¡í„°\n",
    "# z : í‰ê· ê³¼ ë¶„ì‚°ì„ ì‚¬ìš©í•´ ìƒ˜í”Œë§ëœ ì ì¬ ê³µê°„ì˜ ë²¡í„°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ë””ì½”ë” ì •ì˜\n",
    "decoder_input = keras.layers.Input(shape = (latent_dim,), name = 'decoder_input')\n",
    "x = keras.layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
    "# Denseë ˆì´ì–´ë¡œ ì ì¬ê³µê°„ì˜ ë²¡í„°ë¥¼ ë””ì½”ë” ì¶œë ¥ì— ë§ê²Œ ë³€í™˜\n",
    "# prod : ì´ í˜•íƒœì˜ ëª¨ë“  ì°¨ì›ì„ ê³±í•´ 1ì°¨ì› ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "# (16,16,128) -> 16x16x128\n",
    "# ë¨¼ì € ìœ„ì—ì„œ ì €ì¥í–ˆë˜ flattenì „ ë§ˆì§€ë§‰ 3ì°¨ì›ì„ 1ì°¨ì›ìœ¼ë¡œ ë³€í™˜ í›„ Denseë ˆì´ì–´ì— ì ìš©\n",
    "\n",
    "x = keras.layers.Reshape(shape_before_flattening)(x)\n",
    "# ì›ë˜ ì¸ì½”ë”ì˜ ë§ˆì§€ë§‰ ì¶œë ¥ í˜•íƒœì¸ 3ì°¨ì› í…ì„œë¡œ ë‹¤ì‹œ reshape\n",
    "x = keras.layers.Conv2DTranspose(128, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2DTranspose(64, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "x = keras.layers.Conv2DTranspose(32, (3, 3), strides = 2, activation = 'relu', padding='same')(x)\n",
    "\n",
    "decoder_output = keras.layers.Conv2D(3, (3, 3), strides = 1, activation = 'sigmoid', padding='same', name='decoder_output')(x)\n",
    "decoder = keras.models.Model(decoder_input, decoder_output, name = 'decoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. í•™ìŠµ ë£¨í”„ ë§Œë“¤ê¸°\n",
    "def train_step(data):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # with tf.GradientTape() as tape : tensorflowì—ì„œ ìë™ ë¯¸ë¶„ì„ ìœ„í•´ ì„¤ì •í•˜ëŠ” withë¬¸\n",
    "        z_mean, z_log_var, z = encoder(data)\n",
    "        recon = decoder(z)\n",
    "        # recon : ì¬êµ¬ì„±ëœ ì´ë¯¸ì§€ / ì…ë ¥ë°ì´í„°ì™€ ë¹„êµë  ì´ë¯¸ì§€\n",
    "\n",
    "        # 1. ì¬êµ¬ì„± ì†ì‹¤\n",
    "        recon_loss = tf.reduce_mean(500 * tf.losses.binary_crossentropy(data, recon))\n",
    "        # ì›ë³¸ ë°ì´í„°ì™€ ì¬êµ¬ì„±ëœ ì´ë¯¸ì§€ ë°ì´í„° ê°„ì˜ ì°¨ì´ë¥¼\n",
    "        # í”½ì…€ì˜ ì´ì§„ë¶„í¬ë¡œ ê³„ì‚°\n",
    "        # ê°€ì¤‘ì¹˜ë¥¼ 500ê³±í•´ì„œ ì¡°ì •\n",
    "        # reduce_mean : ë°°ì¹˜ ë‚´ ëª¨ë“  ë°ì´í„°í¬ì¸íŠ¸ì˜ í‰ê· ì†ì‹¤ì„ ê³„ì‚°í•œë‹¤ëŠ” ì˜ë¯¸\n",
    "\n",
    "        # 2. KL-ë°œì‚° ì†ì‹¤\n",
    "        kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)), axis = 1))\n",
    "        # axis = 1ì˜µì…˜ì„ ë„£ì—ˆê¸° ë–„ë¬¸ì— ê° ì°¨ì›ì— ëŒ€í•œ í•©ì‚°\n",
    "        total_loss = recon_loss + kl_loss\n",
    "    \n",
    "    grad = tape.gradient(total_loss, encoder.trainable_weights + decoder.trainable_weights)\n",
    "    # tape.gradientëŠ” total_lossì— ëŒ€í•œ ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°\n",
    "    optimizer.apply_gradients(zip(grad, encoder.trainable_weights + decoder.trainable_weights))\n",
    "    # ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ Adamìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸\n",
    "    return total_loss, recon_loss, kl_loss\n",
    "    # ì´ ì†ì‹¤, ì¬êµ¬ì„± ì†ì‹¤, KL-ë°œì‚° ì†ì‹¤ì„ ë°˜í™˜ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(1000).batch(batch_size)\n",
    "# tf.data.Dataset.from_tensor_slices : ì£¼ì–´ì§„ í…ì„œë¥¼ ë°›ì•„ ì´ë¥¼ ê°œë³„ ìŠ¬ë¼ì´ìŠ¤ë¡œ ë‚˜ëˆ  ë°ì´í„°ì…‹ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n",
      "step 0 : total loss = 347.2638,recon loss : 346.6690,KL loss : 0.5948\n",
      "step 100 : total loss = 320.9874,recon loss : 314.6162,KL loss : 6.3712\n",
      "step 200 : total loss = 289.2507,recon loss : 278.3510,KL loss : 10.8997\n",
      "step 300 : total loss = 302.1631,recon loss : 291.7750,KL loss : 10.3881\n",
      "Epoch 2 / 10\n",
      "step 0 : total loss = 307.4444,recon loss : 297.4410,KL loss : 10.0034\n",
      "step 100 : total loss = 286.6945,recon loss : 274.8837,KL loss : 11.8108\n",
      "step 200 : total loss = 290.0837,recon loss : 278.3944,KL loss : 11.6894\n",
      "step 300 : total loss = 295.9551,recon loss : 283.9161,KL loss : 12.0390\n",
      "Epoch 3 / 10\n",
      "step 0 : total loss = 296.9900,recon loss : 283.6467,KL loss : 13.3433\n",
      "step 100 : total loss = 302.9109,recon loss : 290.5237,KL loss : 12.3872\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4208\\2027987251.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch {epoch + 1} / {epochs}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;31m# í˜„ì¬ ìŠ¤íƒ­ê³¼ ë°°ì¹˜ë°ì´í„°ë¥¼ ë°˜í™˜\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecon_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkl_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;31m# ìŠ¤íƒ­ì´ 100ì˜ ë°°ìˆ˜ì¼ ë–„ë§ˆë‹¤\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             print(f'step {step} : total loss = {total_loss.numpy():.4f},'\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4208\\1656924006.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mkl_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mz_log_var\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_mean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz_log_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m# axis = 1ì˜µì…˜ì„ ë„£ì—ˆê¸° ë–„ë¬¸ì— ê° ì°¨ì›ì— ëŒ€í•œ í•©ì‚°\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecon_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mkl_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;31m# tape.gradientëŠ” total_lossì— ëŒ€í•œ ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ê°€ì¤‘ì¹˜ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# ê³„ì‚°ëœ ê¸°ìš¸ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ Adamìµœì í™” ì•Œê³ ë¦¬ì¦˜ì„ í†µí•´ ì¸ì½”ë”ì™€ ë””ì½”ë”ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1096\u001b[0m               output_gradients))\n\u001b[0;32m   1097\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[0;32m   1098\u001b[0m                           for x in output_gradients]\n\u001b[0;32m   1099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise ValueError(\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"gradient_tape/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\ops\\nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m     47\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"padding\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"explicit_paddings\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m           data_format=op.get_attr(\"data_format\").decode()),\n\u001b[1;32m---> 51\u001b[1;33m       gen_nn_ops.conv2d(\n\u001b[0m\u001b[0;32m     52\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dilations\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[0;32m    929\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m       return conv2d_eager_fallback(\n\u001b[0;32m    936\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1} / {epochs}')\n",
    "    for step, batch_data in enumerate(dataset):\n",
    "        # í˜„ì¬ ìŠ¤íƒ­ê³¼ ë°°ì¹˜ë°ì´í„°ë¥¼ ë°˜í™˜\n",
    "        total_loss, recon_loss, kl_loss = train_step(batch_data)\n",
    "        if step % 100 == 0:\n",
    "            # ìŠ¤íƒ­ì´ 100ì˜ ë°°ìˆ˜ì¼ ë–„ë§ˆë‹¤\n",
    "            print(f'step {step} : total loss = {total_loss.numpy():.4f},'\n",
    "                  f'recon loss : {recon_loss.numpy():.4f},'\n",
    "                  f'KL loss : {kl_loss.numpy():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Torchë¥¼ í™œìš©í•œ MNISTë°ì´í„°ì…‹ì— VAE ì ìš©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸŒ¼ë§ˆë¬´ë¦¬ ë¬¸ì œ\n",
    "\n",
    "ë‹¤ì–‘í•œ ë°ì´í„°ì…‹ì„ ì ìš©í•´ë³´ì„¸ìš”\n",
    "\n",
    "Q1. Fashion MNIST\n",
    "- 28X28 í¬ê¸°ì˜ íŒ¨ì…˜ ì•„ì´í…œ ì´ë¯¸ì§€ë¡œ êµ¬ì„±ëœ í‘ë°± ì´ë¯¸ì§€ ë°ì´í„°ì…‹\n",
    "\n",
    "\n",
    "Q2. CIFAR-10\n",
    "- 32X32 í¬ê¸°ì˜ ìƒ‰ìƒì´ ìˆëŠ” ìë™ì°¨, ë™ë¬¼ ë“± ë‹¤ì–‘í•œ ê°ì²´ê°€ í¬í•¨ëœ ë°ì´í„°ì…‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fashion MNIST ë°ì´í„°ì…‹ ë¡œë“œ (28x28 í¬ê¸°ì˜ íŒ¨ì…˜ ì•„ì´í…œ ì´ë¯¸ì§€)\n",
    "trans = transforms.ToTensor()\n",
    "fashion_mnist_data = datasets.FashionMNIST(root='./data', train=True, transform=trans, download=True)\n",
    "data_loader = DataLoader(fashion_mnist_data, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CIFAR-10 ë°ì´í„°ì…‹ ë¡œë“œ (32x32 í¬ê¸°ì˜ ì»¬ëŸ¬ ì´ë¯¸ì§€)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # ë°ì´í„° ì •ê·œí™”\n",
    "])\n",
    "cifar10_data = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "data_loader = DataLoader(cifar10_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
