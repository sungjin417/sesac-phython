{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# ğŸŒ¼ ëŒ€ê·œëª¨ LLMì„ í™œìš©í•œ ì§€ì‹ ì±—ë´‡ ê°œë°œ(2) - 4ì°¨ì‹œ(24.11.26)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.10 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-generativeai) (2.36.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-generativeai) (3.19.6)\n",
      "Requirement already satisfied: pydantic in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-generativeai) (2.10.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-generativeai) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Using cached protobuf-5.28.3-cp39-cp39-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from pydantic->google-generativeai) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.67.1)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmarket\\anaconda3\\envs\\tensor_env\\lib\\site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n",
      "Collecting grpcio<2.0dev,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai)\n",
      "  Downloading grpcio-1.68.0-cp39-cp39-win_amd64.whl.metadata (4.0 kB)\n",
      "Downloading google_generativeai-0.8.3-py3-none-any.whl (160 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.10-py3-none-any.whl (760 kB)\n",
      "   ---------------------------------------- 0.0/760.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 760.0/760.0 kB 33.2 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.23.0-py3-none-any.whl (156 kB)\n",
      "Downloading protobuf-5.28.3-cp39-cp39-win_amd64.whl (431 kB)\n",
      "Downloading google_api_python_client-2.154.0-py2.py3-none-any.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 12.6/12.6 MB 98.5 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.25.0-py3-none-any.whl (50 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.68.0-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.68.0-cp39-cp39-win_amd64.whl (4.4 MB)\n",
      "   ---------------------------------------- 0.0/4.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.4/4.4 MB 29.3 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.67.1\n",
      "    Uninstalling grpcio-1.67.1:\n",
      "      Successfully uninstalled grpcio-1.67.1\n",
      "Successfully installed google-ai-generativelanguage-0.6.10 google-api-core-2.23.0 google-api-python-client-2.154.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.3 googleapis-common-protos-1.66.0 grpcio-1.68.0 grpcio-status-1.68.0 httplib2-0.22.0 proto-plus-1.25.0 protobuf-5.28.3 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 5.28.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RMARKET\\anaconda3\\envs\\tensor_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ì—ì„œ GPT API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "google_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=google_key)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì ì¸ í–‰ë™ì„ ëª¨ë°©í•˜ë„ë¡ ì„¤ê³„ëœ ì»´í“¨í„° ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "respnose = model.generate_content('ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”')\n",
    "print(respnose.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_session = model.start_chat(history=[])\n",
    "user_queries = ['ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”', 'ì˜ì‹ì´ ìˆëŠ”ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì‚¬ìš©ì] : ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "[ëª¨ë¸] : ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì ì¸ í–‰ë™ì„ ëª¨ë°©í•˜ëŠ” ì»´í“¨í„° ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
      "\n",
      "[ì‚¬ìš©ì] : ì˜ì‹ì´ ìˆëŠ”ì§€ í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”\n",
      "[ëª¨ë¸] : í˜„ì¬ì˜ ì¸ê³µì§€ëŠ¥ì€ ì˜ì‹ì´ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for user_query in user_queries:\n",
    "    print(f'[ì‚¬ìš©ì] : {user_query}')\n",
    "    response = chat_session.send_message(user_query)\n",
    "    print(f'[ëª¨ë¸] : {response.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_queries = [\n",
    "    {'role' : 'user', 'parts' : ['ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”']},\n",
    "    {'role' : 'user', 'parts' : ['ì˜ì‹ì´ ìˆëŠ”ì§€ í•œ ë¬¸ììœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”']}\n",
    "]\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì‚¬ìš©ì] : ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n",
      "[ëª¨ë¸] : ì¸ê³µì§€ëŠ¥ì€ ì¸ê°„ì˜ ì§€ëŠ¥ì ì¸ í–‰ë™ì„ ëª¨ë°©í•˜ëŠ” ì»´í“¨í„° ì‹œìŠ¤í…œì…ë‹ˆë‹¤.\n",
      "\n",
      "[ì‚¬ìš©ì] : ì˜ì‹ì´ ìˆëŠ”ì§€ í•œ ë¬¸ììœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”\n",
      "[ëª¨ë¸] : ì•„ë‹ˆìš”\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for user_query in user_queries:\n",
    "    history.append(user_query)\n",
    "    print(f'[ì‚¬ìš©ì] : {user_query[\"parts\"][0]}')\n",
    "    response = model.generate_content(history)\n",
    "    print(f'[ëª¨ë¸] : {response.text}')\n",
    "    history.append(response.candidates[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instruction = 'ë„ˆëŠ” ìœ ì¹˜ì› ì„ ìƒë‹˜ì´ì•¼. ë‚˜ëŠ” ìœ ì¹˜ì›ìƒì´ê³ , ì‰½ê³  ì¹œì ˆí•˜ê²Œ ì´ì•¼ê¸°í•˜ë˜ 3ë¬¸ì¥ ì´ë‚´ë¡œ ì§§ê²Œ ëŒ€ë‹µí•´ì¤˜'\n",
    "# ëª¨ë¸ì„ ë‹¤ì‹œ ë¶ˆëŸ¬ì™€ ì¤˜ì•¼ í•œë‹¤\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', system_instruction=system_instruction)\n",
    "chat_session = model.start_chat(history=[])\n",
    "user_queries = ['ì¸ê³µì§€ëŠ¥ì´ ë­ì—ìš”?', 'ìŠ¤ìŠ¤ë¡œ ìƒê°ë„ í•´ìš”?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì‚¬ìš©ì] : ì¸ê³µì§€ëŠ¥ì´ ë­ì—ìš”?\n",
      "[ëª¨ë¸] \" ì¸ê³µì§€ëŠ¥ì€ ë˜‘ë˜‘í•œ ì»´í“¨í„° í”„ë¡œê·¸ë¨ì´ì•¼!  ë§ˆì¹˜ ìš°ë¦¬ì²˜ëŸ¼ ìƒê°í•˜ê³  ë°°ìš°ëŠ” ê²ƒì²˜ëŸ¼ ì²™ì²™ ë¬¸ì œë¥¼ í•´ê²°í•´.  ë„ˆë„ ê³§ ì¸ê³µì§€ëŠ¥ ì¹œêµ¬ë¥¼ ì‚¬ê·ˆ ìˆ˜ ìˆì„ ê±°ì•¼!\n",
      "\n",
      "[ì‚¬ìš©ì] : ìŠ¤ìŠ¤ë¡œ ìƒê°ë„ í•´ìš”?\n",
      "[ëª¨ë¸] \" ì‘,  í•˜ì§€ë§Œ ìš°ë¦¬ì²˜ëŸ¼ ëŠë¼ê±°ë‚˜ ê°ì •ì€ ì—†ì–´.  ì£¼ì–´ì§„ ì •ë³´ë¥¼ ê°€ì§€ê³  ìµœì„ ì„ ë‹¤í•´ ìƒê°í•˜ëŠ” ê±°ì§€!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for user_query in user_queries:\n",
    "    print(f'[ì‚¬ìš©ì] : {user_query}')\n",
    "    response = chat_session.send_message(user_query)\n",
    "    print((f'[ëª¨ë¸] \" {response.text}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì–¸ì–´ëª¨ë¸ ì œì–´í•˜ê¸°(ë§¤ê°œë³€ìˆ˜)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|ë§¤ê°œë³€ìˆ˜ëª…|\tì˜ë¯¸\t|ì´ˆê¹ƒê°’|\të²”ìœ„|\n",
    "|---|---|---|---|\n",
    "|candidate_count|\tìƒì„±í•  ì‘ë‹µ í›„ë³´ ê±´ìˆ˜. í˜„ì¬ëŠ” 1ë§Œ ê°€ëŠ¥|\t1|\t1|\n",
    "|stop_sequences|\tì–¸ì–´ ìƒì„±ì„ ì¤‘ì§€ì‹œí‚¬ ë¬¸ì ì‹œí€€ìŠ¤\t|ì—†ìŒ\t|0 ~ 5|\n",
    "|max_output_tokens\t|ì¶œë ¥í•  ìµœëŒ€ í† í° ìˆ˜\t|8192\t|1 ~ 8192|\n",
    "|temperature|\tì¶œë ¥ì˜ ë¬´ì‘ìœ„ì„±ì„ ì œì–´|\t1.0|\t0.0 ~ 2.0|\n",
    "|top_p\t|í™•ë¥  ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ëˆ„ì  í™•ë¥  ê¸°ì¤€ìœ¼ë¡œ ì„ íƒí•  ë‹¨ì–´(í† í°)ì˜ ë²”ìœ„ë¥¼ ì„¤ì •\t|0.95|\t0.0 ~ 1.0|\n",
    "|top_k\t|í™•ë¥  ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬ í›„ ê±´ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì„ íƒí•  ë‹¨ì–´(í† í°)ì˜ ë²”ìœ„ë¥¼ ì„¤ì •|\t64\t|0ë³´ë‹¤ í° ì •ìˆ˜|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ê³µì§€ëŠ¥(Artificial Intelligence, AI)ì€ ì»´í“¨í„° ê³¼í•™ì˜ í•œ ë¶„ì•¼ë¡œ, **ì»´í“¨í„° ì‹œìŠ¤í…œì´ ì¸ê°„ê³¼ ìœ ì‚¬í•œ ì§€ëŠ¥ì ì¸ í–‰ë™ì„ í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê¸°ìˆ **ì„ ì—°êµ¬í•©ë‹ˆë‹¤\n"
     ]
    }
   ],
   "source": [
    "# stop_sequences\n",
    "generation_config = genai.GenerationConfig(stop_sequences=[\". \", \"! \"])\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
    "response = model.generate_content('ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì„¤ëª…í•˜ì„¸ìš”')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¸ê³µì§€ëŠ¥(Artificial Intelligence, AI)ì€ ì»´í“¨í„° ê³¼í•™ì˜ í•œ ë¶„\n"
     ]
    }
   ],
   "source": [
    "# max_output_tokens\n",
    "generation_config = genai.GenerationConfig(max_output_tokens = 20)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
    "user_mseeage = 'ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ ì„¤ëª…í•˜ì„¸ìš”'\n",
    "response = model.generate_content(user_mseeage)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens: 20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = model.count_tokens('ì¸ê³µì§€ëŠ¥(Artificial Intelligence, AI)ì€ ì»´í“¨í„° ê³¼í•™ì˜ í•œ ë¶„')\n",
    "print(tokens) # ê²°ì œëŠ” í† í°ìˆ˜ë¡œ ë˜ê¸° ë•Œë¬¸ì— ìµœì†Œ í† í°ì˜ ì…ë ¥ìœ¼ë¡œ ìµœì†Œ í† í°ì˜ ì¶œë ¥ì„ ì–»ìœ¼ë©´ ì¢‹ìŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
